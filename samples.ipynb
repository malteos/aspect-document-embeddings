{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset = 'paperswithcode_aspects'\n",
    "nlp_cache_dir = './data/nlp_cache'\n",
    "\n",
    "index_dir = './output/pwc/whoosh_index'\n",
    "tensorboard_dir = './output/pwc/tensorboard'\n",
    "\n",
    "# SPECTER\n",
    "general_fp = './output/pwc/specter.w2v.txt'  \n",
    "\n",
    "# Fine-tuned Sentence-SciBERT\n",
    "task_fp = './output/pwc/task/1/st_scibert-scivocab-uncased/pwc_id2vec__all_docs.w2v.txt'  # pwc_id2vec__train_and_test.w2v.txt  \n",
    "method_fp = './output/pwc/method/1/st_scibert-scivocab-uncased/pwc_id2vec__all_docs.w2v.txt' \n",
    "dataset_fp = './output/pwc/dataset/1/st_scibert-scivocab-uncased/pwc_id2vec__all_docs.w2v.txt' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = [\n",
    "    'V9yaFJy03j', # Data augmentation for low resource sentiment analysis using generative adversarial networks\n",
    "    '9rB_3A5Wy0',  # Sentiment Analysis of German Twitter\n",
    "    'N0jcCtrbqO',  # Fake News in Social Networks\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datasets import load_dataset\n",
    "from experiments.utils import get_local_hf_dataset_path\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from tqdm.auto import tqdm\n",
    "from paperswithcode import Paper\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_vecs = KeyedVectors.load_word2vec_format(general_fp)\n",
    "task_vecs = KeyedVectors.load_word2vec_format(task_fp)\n",
    "method_vecs = KeyedVectors.load_word2vec_format(method_fp)\n",
    "dataset_vecs = KeyedVectors.load_word2vec_format(dataset_fp)\n",
    "\n",
    "# Normalize vectors\n",
    "general_vecs.init_sims(replace=True)\n",
    "task_vecs.init_sims(replace=True)\n",
    "method_vecs.init_sims(replace=True)\n",
    "dataset_vecs.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pwc_aspects (./data/nlp_cache/pwc_aspects/docs/0.1.0/5a02274a50cfdd54f404ef512e5453e7f1a9db1cef85c4ae2ecd4607bc43943e)\n"
     ]
    }
   ],
   "source": [
    "# Load meta data\n",
    "docs_ds = load_dataset(get_local_hf_dataset_path(hf_dataset),\n",
    "                       name='docs',\n",
    "                       cache_dir=nlp_cache_dir,\n",
    "                          split='docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id2paper = {p['paper_id']: Paper(**p) for p in docs_ds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors\n",
    "max_abstract_length = 200\n",
    "top_k = 5\n",
    "\n",
    "def get_html(rank, paper, score=0., show_details=True):  \n",
    "    details_html = f'''\n",
    "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
    "        <b>Tasks:</b> {\", \".join(paper.aspect_tasks)}\n",
    "        <b>Methods:</b> {\", \".join(paper.aspect_methods)}\n",
    "        <b>Datasets:</b> {\", \".join(paper.aspect_datasets)}\n",
    "        </p><p>\n",
    "        {paper.abstract[:max_abstract_length]} <a href=\"#\" onclick=\"$('#abstract_{paper.paper_id}').toggle();\">...</a>\n",
    "        <span id=\"abstract_{paper.paper_id}\" style=\"display:none\">{paper.abstract[max_abstract_length:]}</span>\n",
    "        </div>\n",
    "        ''' if show_details else ''\n",
    "        \n",
    "    return f'''\n",
    "        <div>\n",
    "        <h3>{rank}. <a href=\"{paper.paper_url}\">{paper.title}</a> <small style=\"background: #eee\">{score:.3f}</small></h3>\n",
    "        {details_html}\n",
    "        </div>\n",
    "        '''\n",
    "    \n",
    "\n",
    "def get_col(nn, rank, show_details=True):\n",
    "    pid, score = nn[rank - 1]\n",
    "    return f'<td style=\"vertical-align: top\">{get_html(rank, paper_id2paper[pid], score, show_details)}</td>'\n",
    "\n",
    "def get_multi_view_html(seed_id, show_details=True):\n",
    "\n",
    "    general_nn = list(general_vecs.most_similar(seed_id, topn=top_k))\n",
    "    task_nn = list(task_vecs.most_similar(seed_id, topn=top_k))\n",
    "    method_nn = list(method_vecs.most_similar(seed_id, topn=top_k))\n",
    "    dataset_nn = list(dataset_vecs.most_similar(seed_id, topn=top_k))\n",
    "    col_width = '25%'\n",
    "\n",
    "    results_html = get_html('Seed', paper_id2paper[seed_id]) + ' <hr />'\n",
    "    \n",
    "    results_html += f'''\n",
    "    <table><thead><tr>\n",
    "    <th width=\"{col_width}\">General purpose</th>\n",
    "    <th width=\"{col_width}\">Task-related</th>\n",
    "    <th width=\"{col_width}\">Method-related</th>\n",
    "    <th width=\"{col_width}\">Dataset-related</th>\n",
    "    </thead><tbody>\n",
    "    '''\n",
    "\n",
    "    for rank in range(1, top_k+1):\n",
    "        results_html += f'<tr style=\"vertical-align: top\">'\n",
    "        results_html += get_col(general_nn, rank, show_details)\n",
    "        results_html += get_col(task_nn, rank, show_details)\n",
    "        results_html += get_col(method_nn, rank, show_details)\n",
    "        results_html += get_col(dataset_nn, rank, show_details)\n",
    "\n",
    "        results_html += f'</tr>'\n",
    "\n",
    "        #break\n",
    "\n",
    "    results_html += '</tbody></table>'\n",
    "\n",
    "    return results_html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "        <h3>Seed. <a href=\"https://paperswithcode.com/paper/data-augmentation-for-low-resource-sentiment\">Data augmentation for low resource sentiment analysis using generative adversarial networks</a> <small style=\"background: #eee\">0.000</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Augmentation, Sentiment Analysis, Text Generation\n",
       "        <b>Methods:</b> Convolution, GAN\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Sentiment analysis is a task that may suffer from a lack of data in certain\n",
       "cases, as the datasets are often generated and annotated by humans. In cases\n",
       "where data is inadequate for training discrimin <a href=\"#\" onclick=\"$('#abstract_V9yaFJy03j').toggle();\">...</a>\n",
       "        <span id=\"abstract_V9yaFJy03j\" style=\"display:none\">ative models, generate models\n",
       "may aid training via data augmentation. Generative Adversarial Networks (GANs)\n",
       "are one such model that has advanced the state of the art in several tasks,\n",
       "including as image and text generation. In this paper, I train GAN models on\n",
       "low resource datasets, then use them for the purpose of data augmentation\n",
       "towards improving sentiment classifier generalization. Given the constraints of\n",
       "limited data, I explore various techniques to train the GAN models. I also\n",
       "present an analysis of the quality of generated GAN data as more training data\n",
       "for the GAN is made available. In this analysis, the generated data is\n",
       "evaluated as a test set (against a model trained on real data points) as well\n",
       "as a training set to train classification models. Finally, I also conduct a\n",
       "visual analysis by projecting the generated and the real data into a\n",
       "two-dimensional space using the t-Distributed Stochastic Neighbor Embedding\n",
       "(t-SNE) method.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "         <hr />\n",
       "    <table><thead><tr>\n",
       "    <th width=\"25%\">General purpose</th>\n",
       "    <th width=\"25%\">Task-related</th>\n",
       "    <th width=\"25%\">Method-related</th>\n",
       "    <th width=\"25%\">Dataset-related</th>\n",
       "    </thead><tbody>\n",
       "    <tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/adversarial-training-for-aspect-based\">Adversarial Training for Aspect-Based Sentiment Analysis with BERT</a> <small style=\"background: #eee\">0.846</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Aspect-Based Sentiment Analysis, Aspect Extraction, Language Modelling, Sentiment Analysis\n",
       "        <b>Methods:</b> Residual Connection, Attention Dropout, Linear Warmup With Linear Decay, Weight Decay, GELU, Dense Connections, Adam, WordPiece, Softmax, Dropout, Multi-Head Attention, Layer Normalization, Scaled Dot-Product Attention, BERT\n",
       "        <b>Datasets:</b> SemEval 2014 Task 4 Sub Task 2\n",
       "        </p><p>\n",
       "        Aspect-Based Sentiment Analysis (ABSA) deals with the extraction of sentiments and their targets. Collecting labeled data for this task in order to help neural networks generalize better can be labori <a href=\"#\" onclick=\"$('#abstract_qm8D98EUZz').toggle();\">...</a>\n",
       "        <span id=\"abstract_qm8D98EUZz\" style=\"display:none\">ous and time-consuming. As an alternative, similar data to the real-world examples can be produced artificially through an adversarial process which is carried out in the embedding space. Although these examples are not real sentences, they have been shown to act as a regularization method which can make neural networks more robust. In this work, we apply adversarial training, which was put forward by Goodfellow et al. (2014), to the post-trained BERT (BERT-PT) language model proposed by Xu et al. (2019) on the two major tasks of Aspect Extraction and Aspect Sentiment Classification in sentiment analysis. After improving the results of post-trained BERT by an ablation study, we propose a novel architecture called BERT Adversarial Training (BAT) to utilize adversarial training in ABSA. The proposed model outperforms post-trained BERT in both tasks. To the best of our knowledge, this is the first study on the application of adversarial training in ABSA.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/not-enough-data-deep-learning-to-the-rescue\">Not Enough Data? Deep Learning to the Rescue!</a> <small style=\"background: #eee\">0.987</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Augmentation, Language Modelling, Text Classification, Text Generation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Based on recent advances in natural language modeling and those in text generation capabilities, we propose a novel data augmentation method for text classification tasks. We use a powerful pre-traine <a href=\"#\" onclick=\"$('#abstract_gf7xMU4ZwW').toggle();\">...</a>\n",
       "        <span id=\"abstract_gf7xMU4ZwW\" style=\"display:none\">d neural network model to artificially synthesize new labeled data for supervised learning. We mainly focus on cases with scarce labeled data. Our method, referred to as language-model-based data augmentation (LAMBADA), involves fine-tuning a state-of-the-art language generator to a specific task through an initial training phase on the existing (usually small) labeled data. Using the fine-tuned model and given a class label, new sentences for the class are generated. Our process then filters these new sentences by using a classifier trained on the original data. In a series of experiments, we show that LAMBADA improves classifiers' performance on a variety of datasets. Moreover, LAMBADA significantly improves upon the state-of-the-art techniques for data augmentation, specifically those applicable to text classification tasks with little data.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/dna-methylation-data-to-predict-suicidal-and\">DNA Methylation Data to Predict Suicidal and Non-Suicidal Deaths: A Machine Learning Approach</a> <small style=\"background: #eee\">0.980</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Visualization, Dimensionality Reduction\n",
       "        <b>Methods:</b> PCA\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The objective of this study is to predict suicidal and non-suicidal deaths from DNA methylation data using a modern machine learning algorithm. We used support vector machines to classify existing sec <a href=\"#\" onclick=\"$('#abstract_fEM5vqSEER').toggle();\">...</a>\n",
       "        <span id=\"abstract_fEM5vqSEER\" style=\"display:none\">ondary data consisting of normalized values of methylated DNA probe intensities from tissues of two cortical brain regions to distinguish suicide cases from control cases. Before classification, we employed Principal component analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE) to reduce the dimension of the data. In comparison to PCA, the modern data visualization method t-SNE performs better in dimensionality reduction. t-SNE accounts for the possible non-linear patterns in low-dimensional data. We applied four-fold cross-validation in which the resulting output from t-SNE was used as training data for the Support Vector Machine (SVM). Despite the use of cross-validation, the nominally perfect prediction of suicidal deaths for BA11 data suggests possible over-fitting of the model. The study also may have suffered from 'spectrum bias' since the individuals were only studied from two extreme scenarios. This research constitutes a baseline study for classifying suicidal and non-suicidal deaths from DNA methylation data. Future studies with larger sample size, while possibly incorporating methylation data from living individuals, may reduce the bias and improve the accuracy of the results.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/semi-supervised-and-transfer-learning\">Semi-supervised and Transfer learning approaches for low resource sentiment classification</a> <small style=\"background: #eee\">0.989</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis, Transfer Learning\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Sentiment classification involves quantifying the affective reaction of a\n",
       "human to a document, media item or an event. Although researchers have\n",
       "investigated several methods to reliably infer sentimen <a href=\"#\" onclick=\"$('#abstract_7XsnAC7rLY').toggle();\">...</a>\n",
       "        <span id=\"abstract_7XsnAC7rLY\" style=\"display:none\">t from lexical, speech\n",
       "and body language cues, training a model with a small set of labeled datasets\n",
       "is still a challenge. For instance, in expanding sentiment analysis to new\n",
       "languages and cultures, it may not always be possible to obtain comprehensive\n",
       "labeled datasets. In this paper, we investigate the application of\n",
       "semi-supervised and transfer learning methods to improve performances on low\n",
       "resource sentiment classification tasks. We experiment with extracting dense\n",
       "feature representations, pre-training and manifold regularization in enhancing\n",
       "the performance of sentiment classification systems. Our goal is a coherent\n",
       "implementation of these methods and we evaluate the gains achieved by these\n",
       "methods in matched setting involving training and testing on a single corpus\n",
       "setting as well as two cross corpora settings. In both the cases, our\n",
       "experiments demonstrate that the proposed methods can significantly enhance the\n",
       "model performance against a purely supervised approach, particularly in cases\n",
       "involving a handful of training data.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/data-augmentation-in-emotion-classification\">Data Augmentation in Emotion Classification Using Generative Adversarial Networks</a> <small style=\"background: #eee\">0.821</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Augmentation, Emotion Classification\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        It is a difficult task to classify images with multiple class labels using\n",
       "only a small number of labeled examples, especially when the label (class)\n",
       "distribution is imbalanced. Emotion classification <a href=\"#\" onclick=\"$('#abstract_w-Zc1jfL_O').toggle();\">...</a>\n",
       "        <span id=\"abstract_w-Zc1jfL_O\" style=\"display:none\"> is such an example of\n",
       "imbalanced label distribution, because some classes of emotions like\n",
       "\\emph{disgusted} are relatively rare comparing to other labels like {\\it happy\n",
       "or sad}. In this paper, we propose a data augmentation method using generative\n",
       "adversarial networks (GAN). It can complement and complete the data manifold\n",
       "and find better margins between neighboring classes. Specifically, we design a\n",
       "framework with a CNN model as the classifier and a cycle-consistent adversarial\n",
       "networks (CycleGAN) as the generator. In order to avoid gradient vanishing\n",
       "problem, we employ the least-squared loss as adversarial loss. We also propose\n",
       "several evaluation methods on three benchmark datasets to validate GAN's\n",
       "performance. Empirical results show that we can obtain 5%~10% increase in the\n",
       "classification accuracy after employing the GAN-based data augmentation\n",
       "techniques.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/text-data-augmentation-towards-better\">Text Data Augmentation: Towards better detection of spear-phishing emails</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Augmentation, Language Modelling, Machine Translation, Question Answering, Text Augmentation, Text Classification\n",
       "        <b>Methods:</b> Multi-Head Attention, Residual Connection, Scaled Dot-Product Attention, Attention Dropout, Weight Decay, Adam, Softmax, WordPiece, Dense Connections, Layer Normalization, GELU, Linear Warmup With Linear Decay, Dropout, BERT\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Text data augmentation, i.e. the creation of synthetic textual data from an original text, is challenging as augmentation transformations should take into account language complexity while being relev <a href=\"#\" onclick=\"$('#abstract_3Fnk_hxWYw').toggle();\">...</a>\n",
       "        <span id=\"abstract_3Fnk_hxWYw\" style=\"display:none\">ant to the target Natural Language Processing (NLP) task (e.g. Machine Translation, Question Answering, Text Classification, etc.). Motivated by a business application of Business Email Compromise (BEC) detection, we propose a corpus and task agnostic text augmentation framework combining different methods, utilizing BERT language model, multi-step back-translation and heuristics. We show that our augmentation framework improves performances on several text classification tasks using publicly available models and corpora (SST2 and TREC) as well as on a BEC detection task. We also provide a comprehensive argumentation about the limitations of our augmentation framework.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/company-classification-using-machine-learning\">Company classification using machine learning</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making, Dimensionality Reduction, Portfolio Optimization\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The recent advancements in computational power and machine learning algorithms have led to vast improvements in manifold areas of research. Especially in finance, the application of machine learning e <a href=\"#\" onclick=\"$('#abstract_mkucvS0Rhm').toggle();\">...</a>\n",
       "        <span id=\"abstract_mkucvS0Rhm\" style=\"display:none\">nables both researchers and practitioners to gain new insights into financial data and well-studied areas such as company classification. In our paper, we demonstrate that unsupervised machine learning algorithms can be used to visualize and classify company data in an economically meaningful and effective way. In particular, we implement the data-driven dimension reduction and visualization tool t-distributed stochastic neighbor embedding (t-SNE) in combination with spectral clustering. The resulting company groups can then be utilized by experts in the field for empirical analysis and optimal decision making. By providing an exemplary out-of-sample study within a portfolio optimization framework, we show that the application of t-SNE and spectral clustering improves the overall portfolio performance. Therefore, we introduce our approach to the financial community as a valuable technique in the context of data analysis and company classification.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/affection-driven-neural-networks-for\">Affection Driven Neural Networks for Sentiment Analysis</a> <small style=\"background: #eee\">0.988</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis\n",
       "        <b>Methods:</b> Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep neural network models have played a critical role in sentiment analysis with promising results in the recent decade. One of the essential challenges, however, is how external sentiment knowledge  <a href=\"#\" onclick=\"$('#abstract_MhHP4rv9wG').toggle();\">...</a>\n",
       "        <span id=\"abstract_MhHP4rv9wG\" style=\"display:none\">can be effectively utilized. In this work, we propose a novel affection-driven approach to incorporating affective knowledge into neural network models. The affective knowledge is obtained in the form of a lexicon under the Affect Control Theory (ACT), which is represented by vectors of three-dimensional attributes in Evaluation, Potency, and Activity (EPA). The EPA vectors are mapped to an affective influence value and then integrated into Long Short-term Memory (LSTM) models to highlight affective terms. Experimental results show a consistent improvement of our approach over conventional LSTM models by 1.0{\\%} to 1.5{\\%} in accuracy on three large benchmark datasets. Evaluations across a variety of algorithms have also proven the effectiveness of leveraging affective terms for deep model enhancement.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/hierarchical-attention-generative-adversarial\">Hierarchical Attention Generative Adversarial Networks for Cross-domain Sentiment Classification</a> <small style=\"background: #eee\">0.817</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Domain Adaptation, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Cross-domain sentiment classification (CDSC) is an importance task in domain\n",
       "adaptation and sentiment classification. Due to the domain discrepancy, a\n",
       "sentiment classifier trained on source domain dat <a href=\"#\" onclick=\"$('#abstract_e5-jXeBiuH').toggle();\">...</a>\n",
       "        <span id=\"abstract_e5-jXeBiuH\" style=\"display:none\">a may not works well on target\n",
       "domain data. In recent years, many researchers have used deep neural network\n",
       "models for cross-domain sentiment classification task, many of which use\n",
       "Gradient Reversal Layer (GRL) to design an adversarial network structure to\n",
       "train a domain-shared sentiment classifier. Different from those methods, we\n",
       "proposed Hierarchical Attention Generative Adversarial Networks (HAGAN) which\n",
       "alternately trains a generator and a discriminator in order to produce a\n",
       "document representation which is sentiment-distinguishable but\n",
       "domain-indistinguishable. Besides, the HAGAN model applies Bidirectional Gated\n",
       "Recurrent Unit (Bi-GRU) to encode the contextual information of a word and a\n",
       "sentence into the document representation. In addition, the HAGAN model use\n",
       "hierarchical attention mechanism to optimize the document representation and\n",
       "automatically capture the pivots and non-pivots. The experiments on Amazon\n",
       "review dataset show the effectiveness of HAGAN.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/conditional-bert-contextual-augmentation\">Conditional BERT Contextual Augmentation</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Augmentation, Language Modelling, Text Classification\n",
       "        <b>Methods:</b> Residual Connection, Attention Dropout, Linear Warmup With Linear Decay, Weight Decay, GELU, Dense Connections, Adam, WordPiece, Softmax, Dropout, Multi-Head Attention, Layer Normalization, Scaled Dot-Product Attention, BERT\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We propose a novel data augmentation method for labeled sentences called\n",
       "conditional BERT contextual augmentation. Data augmentation methods are often\n",
       "applied to prevent overfitting and improve genera <a href=\"#\" onclick=\"$('#abstract_GqOjh8xz3S').toggle();\">...</a>\n",
       "        <span id=\"abstract_GqOjh8xz3S\" style=\"display:none\">lization of deep neural\n",
       "network models. Recently proposed contextual augmentation augments labeled\n",
       "sentences by randomly replacing words with more varied substitutions predicted\n",
       "by language model. BERT demonstrates that a deep bidirectional language model\n",
       "is more powerful than either an unidirectional language model or the shallow\n",
       "concatenation of a forward and backward model. We retrofit BERT to conditional\n",
       "BERT by introducing a new conditional masked language model\\footnote{The term\n",
       "\"conditional masked language model\" appeared once in original BERT paper, which\n",
       "indicates context-conditional, is equivalent to term \"masked language model\".\n",
       "In our paper, \"conditional masked language model\" indicates we apply extra\n",
       "label-conditional constraint to the \"masked language model\".} task. The well\n",
       "trained conditional BERT can be applied to enhance contextual augmentation.\n",
       "Experiments on six various different text classification tasks show that our\n",
       "method can be easily applied to both convolutional or recurrent neural networks\n",
       "classifier to obtain obvious improvement.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/inductive-hashing-on-manifolds\">Inductive Hashing on Manifolds</a> <small style=\"background: #eee\">0.977</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Learning based hashing methods have attracted considerable attention due to\n",
       "their ability to greatly increase the scale at which existing algorithms may\n",
       "operate. Most of these methods are designed to  <a href=\"#\" onclick=\"$('#abstract_fONgcUI38z').toggle();\">...</a>\n",
       "        <span id=\"abstract_fONgcUI38z\" style=\"display:none\">generate binary codes that\n",
       "preserve the Euclidean distance in the original space. Manifold learning\n",
       "techniques, in contrast, are better able to model the intrinsic structure\n",
       "embedded in the original high-dimensional data. The complexity of these models,\n",
       "and the problems with out-of-sample data, have previously rendered them\n",
       "unsuitable for application to large-scale embedding, however. In this work, we\n",
       "consider how to learn compact binary embeddings on their intrinsic manifolds.\n",
       "In order to address the above-mentioned difficulties, we describe an efficient,\n",
       "inductive solution to the out-of-sample data problem, and a process by which\n",
       "non-parametric manifold learning may be used as the basis of a hashing method.\n",
       "Our proposed approach thus allows the development of a range of new hashing\n",
       "techniques exploiting the flexibility of the wide variety of manifold learning\n",
       "approaches available. We particularly show that hashing on the basis of t-SNE .</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/learning-representations-for-sentiment\">Learning representations for sentiment classification using Multi-task framework</a> <small style=\"background: #eee\">0.987</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Multi-Task Learning, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Most of the existing state of the art sentiment classification techniques involve the use of pre-trained embeddings. This paper postulates a generalized representation that collates training on multip <a href=\"#\" onclick=\"$('#abstract_qJONgqTs8b').toggle();\">...</a>\n",
       "        <span id=\"abstract_qJONgqTs8b\" style=\"display:none\">le datasets using a Multi-task learning framework. We incorporate publicly available, pre-trained embeddings with Bidirectional LSTM{'}s to develop the multi-task model. We validate the representations on an independent test Irony dataset that can contain several sentiments within each sample, with an arbitrary distribution. Our experiments show a significant improvement in results as compared to the available baselines for individual datasets on which independent models are trained. Results also suggest superior performance of the representations generated over Irony dataset.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/semi-supervised-and-transfer-learning\">Semi-supervised and Transfer learning approaches for low resource sentiment classification</a> <small style=\"background: #eee\">0.816</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis, Transfer Learning\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Sentiment classification involves quantifying the affective reaction of a\n",
       "human to a document, media item or an event. Although researchers have\n",
       "investigated several methods to reliably infer sentimen <a href=\"#\" onclick=\"$('#abstract_7XsnAC7rLY').toggle();\">...</a>\n",
       "        <span id=\"abstract_7XsnAC7rLY\" style=\"display:none\">t from lexical, speech\n",
       "and body language cues, training a model with a small set of labeled datasets\n",
       "is still a challenge. For instance, in expanding sentiment analysis to new\n",
       "languages and cultures, it may not always be possible to obtain comprehensive\n",
       "labeled datasets. In this paper, we investigate the application of\n",
       "semi-supervised and transfer learning methods to improve performances on low\n",
       "resource sentiment classification tasks. We experiment with extracting dense\n",
       "feature representations, pre-training and manifold regularization in enhancing\n",
       "the performance of sentiment classification systems. Our goal is a coherent\n",
       "implementation of these methods and we evaluate the gains achieved by these\n",
       "methods in matched setting involving training and testing on a single corpus\n",
       "setting as well as two cross corpora settings. In both the cases, our\n",
       "experiments demonstrate that the proposed methods can significantly enhance the\n",
       "model performance against a purely supervised approach, particularly in cases\n",
       "involving a handful of training data.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/improving-short-text-classification-through\">Improving short text classification through global augmentation methods</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Text Augmentation, Text Classification\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We study the effect of different approaches to text augmentation. To do this we use 3 datasets that include social media and formal text in the form of news articles. Our goal is to provide insights f <a href=\"#\" onclick=\"$('#abstract_W9uFm3KajG').toggle();\">...</a>\n",
       "        <span id=\"abstract_W9uFm3KajG\" style=\"display:none\">or practitioners and researchers on making choices for augmentation for classification use cases. We observe that Word2vec-based augmentation is a viable option when one does not have access to a formal synonym model (like WordNet-based augmentation). The use of \\emph{mixup} further improves performance of all text based augmentations and reduces the effects of overfitting on a tested deep learning model. Round-trip translation with a translation service proves to be harder to use due to cost and as such is less accessible for both normal and low resource use-cases.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/t-sne-cuda-gpu-accelerated-t-sne-and-its\">t-SNE-CUDA: GPU-Accelerated t-SNE and its Applications to Modern Data</a> <small style=\"background: #eee\">0.976</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Dimensionality Reduction\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Modern datasets and models are notoriously difficult to explore and analyze\n",
       "due to their inherent high dimensionality and massive numbers of samples.\n",
       "Existing visualization methods which employ dimens <a href=\"#\" onclick=\"$('#abstract_83ivZp0ZnJ').toggle();\">...</a>\n",
       "        <span id=\"abstract_83ivZp0ZnJ\" style=\"display:none\">ionality reduction to two or\n",
       "three dimensions are often inefficient and/or ineffective for these datasets.\n",
       "This paper introduces t-SNE-CUDA, a GPU-accelerated implementation of\n",
       "t-distributed Symmetric Neighbor Embedding (t-SNE) for visualizing datasets and\n",
       "models. t-SNE-CUDA significantly outperforms current implementations with\n",
       "50-700x speedups on the CIFAR-10 and MNIST datasets. These speedups enable, for\n",
       "the first time, visualization of the neural network activations on the entire\n",
       "ImageNet dataset - a feat that was previously computationally intractable. We\n",
       "also demonstrate visualization performance in the NLP domain by visualizing the\n",
       "GloVe embedding vectors. From these visualizations, we can draw interesting\n",
       "conclusions about using the L2 metric in these embedding spaces. t-SNE-CUDA is\n",
       "publicly available athttps://github.com/CannyLab/tsne-cuda</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/learning-with-noisy-labels-for-sentence-level\">Learning with Noisy Labels for Sentence-level Sentiment Classification</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Learning with noisy labels, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep neural networks (DNNs) can fit (or even over-fit) the training data very well. If a DNN model is trained using data with noisy labels and tested on data with clean labels, the model may perform p <a href=\"#\" onclick=\"$('#abstract_QsgiMgaiFb').toggle();\">...</a>\n",
       "        <span id=\"abstract_QsgiMgaiFb\" style=\"display:none\">oorly. This paper studies the problem of learning with noisy labels for sentence-level sentiment classification. We propose a novel DNN model called NetAb (as shorthand for convolutional neural Networks with Ab-networks) to handle noisy labels during training. NetAb consists of two convolutional neural networks, one with a noise transition layer for dealing with the input noisy labels and the other for predicting 'clean' labels. We train the two networks using their respective loss functions in a mutual reinforcement manner. Experimental results demonstrate the effectiveness of the proposed model.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/on-enhancing-speech-emotion-recognition-using\">On Enhancing Speech Emotion Recognition using Generative Adversarial Networks</a> <small style=\"background: #eee\">0.815</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Emotion Recognition, Speech Emotion Recognition\n",
       "        <b>Methods:</b> Convolution, GAN\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Generative Adversarial Networks (GANs) have gained a lot of attention from\n",
       "machine learning community due to their ability to learn and mimic an input\n",
       "data distribution. GANs consist of a discriminato <a href=\"#\" onclick=\"$('#abstract_LqfNCGfyAz').toggle();\">...</a>\n",
       "        <span id=\"abstract_LqfNCGfyAz\" style=\"display:none\">r and a generator working in\n",
       "tandem playing a min-max game to learn a target underlying data distribution;\n",
       "when fed with data-points sampled from a simpler distribution (like uniform or\n",
       "Gaussian distribution). Once trained, they allow synthetic generation of\n",
       "examples sampled from the target distribution. We investigate the application\n",
       "of GANs to generate synthetic feature vectors used for speech emotion\n",
       "recognition. Specifically, we investigate two set ups: (i) a vanilla GAN that\n",
       "learns the distribution of a lower dimensional representation of the actual\n",
       "higher dimensional feature vector and, (ii) a conditional GAN that learns the\n",
       "distribution of the higher dimensional feature vectors conditioned on the\n",
       "labels or the emotional class to which it belongs. As a potential practical\n",
       "application of these synthetically generated samples, we measure any\n",
       "improvement in a classifier's performance when the synthetic data is used along\n",
       "with real data for training. We perform cross-validation analyses followed by a\n",
       "cross-corpus study.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/contextual-augmentation-data-augmentation-by\">Contextual Augmentation: Data Augmentation by Words with Paradigmatic Relations</a> <small style=\"background: #eee\">0.985</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Data Augmentation, Language Modelling, Text Augmentation, Text Classification\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We propose a novel data augmentation for labeled sentences called contextual\n",
       "augmentation. We assume an invariance that sentences are natural even if the\n",
       "words in the sentences are replaced with other <a href=\"#\" onclick=\"$('#abstract_YJR6_YweyQ').toggle();\">...</a>\n",
       "        <span id=\"abstract_YJR6_YweyQ\" style=\"display:none\"> words with paradigmatic\n",
       "relations. We stochastically replace words with other words that are predicted\n",
       "by a bi-directional language model at the word positions. Words predicted\n",
       "according to a context are numerous but appropriate for the augmentation of the\n",
       "original words. Furthermore, we retrofit a language model with a\n",
       "label-conditional architecture, which allows the model to augment sentences\n",
       "without breaking the label-compatibility. Through the experiments for six\n",
       "various different text classification tasks, we demonstrate that the proposed\n",
       "method improves classifiers based on the convolutional or recurrent neural\n",
       "networks.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/hashing-on-nonlinear-manifolds\">Hashing on Nonlinear Manifolds</a> <small style=\"background: #eee\">0.975</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Image Classification, Quantization, Semantic Retrieval\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Learning based hashing methods have attracted considerable attention due to\n",
       "their ability to greatly increase the scale at which existing algorithms may\n",
       "operate. Most of these methods are designed to  <a href=\"#\" onclick=\"$('#abstract_8LSEgPFuUu').toggle();\">...</a>\n",
       "        <span id=\"abstract_8LSEgPFuUu\" style=\"display:none\">generate binary codes preserving\n",
       "the Euclidean similarity in the original space. Manifold learning techniques,\n",
       "in contrast, are better able to model the intrinsic structure embedded in the\n",
       "original high-dimensional data. The complexities of these models, and the\n",
       "problems with out-of-sample data, have previously rendered them unsuitable for\n",
       "application to large-scale embedding, however. In this work, how to learn\n",
       "compact binary embeddings on their intrinsic manifolds is considered. In order\n",
       "to address the above-mentioned difficulties, an efficient, inductive solution\n",
       "to the out-of-sample data problem, and a process by which non-parametric\n",
       "manifold learning may be used as the basis of a hashing method is proposed. The\n",
       "proposed approach thus allows the development of a range of new hashing\n",
       "techniques exploiting the flexibility of the wide variety of manifold learning\n",
       "approaches available. It is particularly shown that hashing on the basis of\n",
       "t-SNE outperforms state-of-the-art hashing methods on large-scale benchmark\n",
       "datasets, and is very effective for image classification with very short code\n",
       "lengths. The proposed hashing framework is shown to be easily improved, for\n",
       "example, by minimizing the quantization error with learned orthogonal\n",
       "rotations. In addition, a supervised inductive manifold hashing framework is\n",
       "developed by incorporating the label information, which is shown to greatly\n",
       "advance the semantic retrieval performance.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/audio-text-sentiment-analysis-using-deep\">Complementary Fusion of Multi-Features and Multi-Modalities in Sentiment Analysis</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Emotion Recognition, Multimodal Emotion Recognition, Multimodal Sentiment Analysis, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Sentiment analysis, mostly based on text, has been rapidly developing in the last decade and has attracted widespread attention in both academia and industry. However, the information in the real worl <a href=\"#\" onclick=\"$('#abstract_1oi1i7dDUp').toggle();\">...</a>\n",
       "        <span id=\"abstract_1oi1i7dDUp\" style=\"display:none\">d usually comes from multiple modalities, such as audio and text. Therefore, in this paper, based on audio and text, we consider the task of multimodal sentiment analysis and propose a novel fusion strategy including both multi-feature fusion and multi-modality fusion to improve the accuracy of audio-text sentiment analysis. We call it the DFF-ATMF (Deep Feature Fusion - Audio and Text Modality Fusion) model, which consists of two parallel branches, the audio modality based branch and the text modality based branch. Its core mechanisms are the fusion of multiple feature vectors and multiple modality attention. Experiments on the CMU-MOSI dataset and the recently released CMU-MOSEI dataset, both collected from YouTube for sentiment analysis, show the very competitive results of our DFF-ATMF model. Furthermore, by virtue of attention weight distribution heatmaps, we also demonstrate the deep features learned by using DFF-ATMF are complementary to each other and robust. Surprisingly, DFF-ATMF also achieves new state-of-the-art results on the IEMOCAP dataset, indicating that the proposed fusion strategy also has a good generalization ability for multimodal emotion recognition.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "        <h3>Seed. <a href=\"https://paperswithcode.com/paper/sentiment-analysis-of-german-twitter\">Sentiment Analysis of German Twitter</a> <small style=\"background: #eee\">0.000</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Opinion Mining, Sentiment Analysis\n",
       "        <b>Methods:</b> CRF\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This thesis explores the ways by how people express their opinions on German Twitter, examines current approaches to automatic mining of these feelings, and proposes novel methods, which outperform st <a href=\"#\" onclick=\"$('#abstract_9rB_3A5Wy0').toggle();\">...</a>\n",
       "        <span id=\"abstract_9rB_3A5Wy0\" style=\"display:none\">ate-of-the-art techniques. For this purpose, I introduce a new corpus of German tweets that have been manually annotated with sentiments, their targets and holders, as well as polar terms and their contextual modifiers. Using these data, I explore four major areas of sentiment research: (i) generation of sentiment lexicons, (ii) fine-grained opinion mining, (iii) message-level polarity classification, and (iv) discourse-aware sentiment analysis. In the first task, I compare three popular groups of lexicon generation methods: dictionary-, corpus-, and word-embedding-based ones, finding that dictionary-based systems generally yield better lexicons than the last two groups. Apart from this, I propose a linear projection algorithm, whose results surpass many existing automatic lexicons. Afterwords, in the second task, I examine two common approaches to automatic prediction of sentiments, sources, and targets: conditional random fields and recurrent neural networks, obtaining higher scores with the former model and improving these results even further by redefining the structure of CRF graphs. When dealing with message-level polarity classification, I juxtapose three major sentiment paradigms: lexicon-, machine-learning-, and deep-learning-based systems, and try to unite the first and last of these groups by introducing a bidirectional neural network with lexicon-based attention. Finally, in order to make the new classifier aware of discourse structure, I let it separately analyze the elementary discourse units of each microblog and infer the overall polarity of a message from the scores of its EDUs with the help of two new approaches: latent-marginalized CRFs and Recursive Dirichlet Process.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "         <hr />\n",
       "    <table><thead><tr>\n",
       "    <th width=\"25%\">General purpose</th>\n",
       "    <th width=\"25%\">Task-related</th>\n",
       "    <th width=\"25%\">Method-related</th>\n",
       "    <th width=\"25%\">Dataset-related</th>\n",
       "    </thead><tbody>\n",
       "    <tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/comparing-methods-for-twitter-sentiment\">Comparing methods for Twitter Sentiment Analysis</a> <small style=\"background: #eee\">0.873</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis, Twitter Sentiment Analysis\n",
       "        <b>Methods:</b> SVM, Logistic Regression\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This work extends the set of works which deal with the popular problem of\n",
       "sentiment analysis in Twitter. It investigates the most popular document\n",
       "(\"tweet\") representation methods which feed sentiment <a href=\"#\" onclick=\"$('#abstract_q-PDktymH3').toggle();\">...</a>\n",
       "        <span id=\"abstract_q-PDktymH3\" style=\"display:none\"> evaluation mechanisms. In\n",
       "particular, we study the bag-of-words, n-grams and n-gram graphs approaches and\n",
       "for each of them we evaluate the performance of a lexicon-based and 7\n",
       "learning-based classification algorithms (namely SVM, Na\\\"ive Bayesian\n",
       "Networks, Logistic Regression, Multilayer Perceptrons, Best-First Trees,\n",
       "Functional Trees and C4.5) as well as their combinations, using a set of 4451\n",
       "manually annotated tweets. The results demonstrate the superiority of\n",
       "learning-based methods and in particular of n-gram graphs approaches for\n",
       "predicting the sentiment of tweets. They also show that the combinatory\n",
       "approach has impressive effects on n-grams, raising the confidence up to 83.15%\n",
       "on the 5-Grams, using majority vote and a balanced dataset (equal number of\n",
       "positive, negative and neutral tweets for training). In the n-gram graph cases\n",
       "the improvement was small to none, reaching 94.52% on the 4-gram graphs, using\n",
       "Orthodromic distance and a threshold of 0.001.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/opinion-mining-on-non-english-short-text\">Opinion Mining on Non-English Short Text</a> <small style=\"background: #eee\">0.993</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Opinion Mining, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        As the type and the number of such venues increase, automated analysis of\n",
       "sentiment on textual resources has become an essential data mining task. In\n",
       "this paper, we investigate the problem of mining o <a href=\"#\" onclick=\"$('#abstract_GiB-nNlrLX').toggle();\">...</a>\n",
       "        <span id=\"abstract_GiB-nNlrLX\" style=\"display:none\">pinions on the collection of\n",
       "informal short texts. Both positive and negative sentiment strength of texts\n",
       "are detected. We focus on a non-English language that has few resources for\n",
       "text mining. This approach would help enhance the sentiment analysis in\n",
       "languages where a list of opinionated words does not exist. We propose a new\n",
       "method projects the text into dense and low dimensional feature vectors\n",
       "according to the sentiment strength of the words. We detect the mixture of\n",
       "positive and negative sentiments on a multi-variant scale. Empirical evaluation\n",
       "of the proposed framework on Turkish tweets shows that our approach gets good\n",
       "results for opinion mining.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/victor-a-dataset-for-brazilian-legal\">VICTOR: a Dataset for Brazilian Legal Documents Classification</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> BVICTOR, MVICTOR (theme), SVICTOR (theme), MVICTOR (type), SVICTOR (type)\n",
       "        </p><p>\n",
       "        This paper describes VICTOR, a novel dataset built from Brazil{'}s Supreme Court digitalized legal documents, composed of more than 45 thousand appeals, which includes roughly 692 thousand documents{- <a href=\"#\" onclick=\"$('#abstract_GRCI9UNuT3').toggle();\">...</a>\n",
       "        <span id=\"abstract_GRCI9UNuT3\" style=\"display:none\">--}about 4.6 million pages. The dataset contains labeled text data and supports two types of tasks: document type classification; and theme assignment, a multilabel problem. We present baseline results using bag-of-words models, convolutional neural networks, recurrent neural networks and boosting algorithms. We also experiment using linear-chain Conditional Random Fields to leverage the sequential nature of the lawsuits, which we find to lead to improvements on document type classification. Finally we compare a theme classification approach where we use domain knowledge to filter out the less informative document pages to the default one where we use all pages. Contrary to the Court experts{'} expectations, we find that using all available data is the better method. We make the dataset available in three versions of different sizes and contents to encourage explorations of better models and techniques.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/a-simple-approach-to-multilingual-polarity\">A Simple Approach to Multilingual Polarity Classification in Twitter</a> <small style=\"background: #eee\">0.988</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Recently, sentiment analysis has received a lot of attention due to the\n",
       "interest in mining opinions of social media users. Sentiment analysis consists\n",
       "in determining the polarity of a given text, i.e. <a href=\"#\" onclick=\"$('#abstract_spEPjgwbC1').toggle();\">...</a>\n",
       "        <span id=\"abstract_spEPjgwbC1\" style=\"display:none\">, its degree of positiveness\n",
       "or negativeness. Traditionally, Sentiment Analysis algorithms have been\n",
       "tailored to a specific language given the complexity of having a number of\n",
       "lexical variations and errors introduced by the people generating content. In\n",
       "this contribution, our aim is to provide a simple to implement and easy to use\n",
       "multilingual framework, that can serve as a baseline for sentiment analysis\n",
       "contests, and as starting point to build new sentiment analysis systems. We\n",
       "compare our approach in eight different languages, three of them have important\n",
       "international contests, namely, SemEval (English), TASS (Spanish), and\n",
       "SENTIPOLC (Italian). Within the competitions our approach reaches from medium\n",
       "to high positions in the rankings; whereas in the remaining languages our\n",
       "approach outperforms the reported results.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/a-simple-approach-to-multilingual-polarity\">A Simple Approach to Multilingual Polarity Classification in Twitter</a> <small style=\"background: #eee\">0.863</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Recently, sentiment analysis has received a lot of attention due to the\n",
       "interest in mining opinions of social media users. Sentiment analysis consists\n",
       "in determining the polarity of a given text, i.e. <a href=\"#\" onclick=\"$('#abstract_spEPjgwbC1').toggle();\">...</a>\n",
       "        <span id=\"abstract_spEPjgwbC1\" style=\"display:none\">, its degree of positiveness\n",
       "or negativeness. Traditionally, Sentiment Analysis algorithms have been\n",
       "tailored to a specific language given the complexity of having a number of\n",
       "lexical variations and errors introduced by the people generating content. In\n",
       "this contribution, our aim is to provide a simple to implement and easy to use\n",
       "multilingual framework, that can serve as a baseline for sentiment analysis\n",
       "contests, and as starting point to build new sentiment analysis systems. We\n",
       "compare our approach in eight different languages, three of them have important\n",
       "international contests, namely, SemEval (English), TASS (Spanish), and\n",
       "SENTIPOLC (Italian). Within the competitions our approach reaches from medium\n",
       "to high positions in the rankings; whereas in the remaining languages our\n",
       "approach outperforms the reported results.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/a-scalable-lexicon-based-technique-for\">A Scalable, Lexicon Based Technique for Sentiment Analysis</a> <small style=\"background: #eee\">0.992</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Opinion Mining, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Rapid increase in the volume of sentiment rich social media on the web has\n",
       "resulted in an increased interest among researchers regarding Sentimental\n",
       "Analysis and opinion mining. However, with so much  <a href=\"#\" onclick=\"$('#abstract_4bTx8tRVYT').toggle();\">...</a>\n",
       "        <span id=\"abstract_4bTx8tRVYT\" style=\"display:none\">social media available on\n",
       "the web, sentiment analysis is now considered as a big data task. Hence the\n",
       "conventional sentiment analysis approaches fails to efficiently handle the vast\n",
       "amount of sentiment data available now a days. The main focus of the research\n",
       "was to find such a technique that can efficiently perform sentiment analysis on\n",
       "big data sets. A technique that can categorize the text as positive, negative\n",
       "and neutral in a fast and accurate manner. In the research, sentiment analysis\n",
       "was performed on a large data set of tweets using Hadoop and the performance of\n",
       "the technique was measured in form of speed and accuracy. The experimental\n",
       "results shows that the technique exhibits very good efficiency in handling big\n",
       "sentiment data sets.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/semi-supervised-named-entity-recognition-in\">Semi-supervised Named Entity Recognition in noisy-text</a> <small style=\"background: #eee\">0.984</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Named Entity Recognition\n",
       "        <b>Methods:</b> Dropout\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Many of the existing Named Entity Recognition (NER) solutions are built based on news corpus data with proper syntax. These solutions might not lead to highly accurate results when being applied to no <a href=\"#\" onclick=\"$('#abstract_k1BduYerxF').toggle();\">...</a>\n",
       "        <span id=\"abstract_k1BduYerxF\" style=\"display:none\">isy, user generated data, e.g., tweets, which can feature sloppy spelling, concept drift, and limited contextualization of terms and concepts due to length constraints. The models described in this paper are based on linear chain conditional random fields (CRFs), use the BIEOU encoding scheme, and leverage random feature dropout for up-sampling the training data. The considered features include word clusters and pre-trained distributed word representations, updated gazetteer features, and global context predictions. The latter feature allows for ingesting the meaning of new or rare tokens into the system via unsupervised learning and for alleviating the need to learn lexicon based features, which usually tend to be high dimensional. In this paper, we report on the solution [ST] we submitted to the WNUT 2016 NER shared task. We also present an improvement over our original submission [SI], which we built by using semi-supervised learning on labelled training data and pre-trained resourced constructed from unlabelled tweet data. Our ST solution achieved an F1 score of 1.2{\\%} higher than the baseline (35.1{\\%} F1) for the task of extracting 10 entity types. The SI resulted in an increase of 8.2{\\%} in F1 score over the base-line (7.08{\\%} over ST). Finally, the SI model{'}s evaluation on the test data achieved a F1 score of 47.3{\\%} ({\\textasciitilde}1.15{\\%} increase over the 2nd best submitted solution). Our experimental setup and results are available as a standalone twitter NER tool at \\url{https://github.com/napsternxg/TwitterNER}.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/using-hadoop-for-large-scale-analysis-on\">Using Hadoop for Large Scale Analysis on Twitter: A Technical Report</a> <small style=\"background: #eee\">0.988</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making, Opinion Mining, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Sentiment analysis (or opinion mining) on Twitter data has attracted much\n",
       "attention recently. One of the system's key features, is the immediacy in\n",
       "communication with other users in an easy, user-frie <a href=\"#\" onclick=\"$('#abstract_0-lh44Bacm').toggle();\">...</a>\n",
       "        <span id=\"abstract_0-lh44Bacm\" style=\"display:none\">ndly and fast way.\n",
       "Consequently, people tend to express their feelings freely, which makes Twitter\n",
       "an ideal source for accumulating a vast amount of opinions towards a wide\n",
       "diversity of topics. This amount of information offers huge potential and can\n",
       "be harnessed to receive the sentiment tendency towards these topics. However,\n",
       "since none can invest an infinite amount of time to read through these tweets,\n",
       "an automated decision making approach is necessary. Nevertheless, most existing\n",
       "solutions are limited in centralized environments only. Thus, they can only\n",
       "process at most a few thousand tweets. Such a sample, is not representative to\n",
       "define the sentiment polarity towards a topic due to the massive number of\n",
       "tweets published daily. In this paper, we go one step further and develop a\n",
       "novel method for sentiment learning in the MapReduce framework. Our algorithm\n",
       "exploits the hashtags and emoticons inside a tweet, as sentiment labels, and\n",
       "proceeds to a classification procedure of diverse sentiment types in a parallel\n",
       "and distributed manner. Moreover, we utilize Bloom filters to compact the\n",
       "storage size of intermediate data and boost the performance of our algorithm.\n",
       "Through an extensive experimental evaluation, we prove that our solution is\n",
       "efficient, robust and scalable and confirm the quality of our sentiment\n",
       "identification.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/generating-sentiment-lexicons-for-german\">Generating Sentiment Lexicons for German Twitter</a> <small style=\"background: #eee\">0.846</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Despite a substantial progress made in developing new sentiment lexicon\n",
       "generation (SLG) methods for English, the task of transferring these approaches\n",
       "to other languages and domains in a sound way st <a href=\"#\" onclick=\"$('#abstract_dLO6tAhZJK').toggle();\">...</a>\n",
       "        <span id=\"abstract_dLO6tAhZJK\" style=\"display:none\">ill remains open. In this\n",
       "paper, we contribute to the solution of this problem by systematically\n",
       "comparing semi-automatic translations of common English polarity lists with the\n",
       "results of the original automatic SLG algorithms, which were applied directly\n",
       "to German data. We evaluate these lexicons on a corpus of 7,992 manually\n",
       "annotated tweets. In addition to that, we also collate the results of\n",
       "dictionary- and corpus-based SLG methods in order to find out which of these\n",
       "paradigms is better suited for the inherently noisy domain of social media. Our\n",
       "experiments show that semi-automatic translations notably outperform automatic\n",
       "systems (reaching a macro-averaged F1-score of 0.589), and that\n",
       "dictionary-based techniques produce much better polarity lists as compared to\n",
       "corpus-based approaches (whose best F1-scores run up to 0.479 and 0.419\n",
       "respectively) even for the non-standard Twitter genre.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/adapting-freely-available-resources-to-build\">Adapting Freely Available Resources to Build an Opinion Mining Pipeline in Portuguese</a> <small style=\"background: #eee\">0.991</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Named Entity Recognition, Opinion Mining, Part-Of-Speech Tagging, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We present a complete UIMA-based pipeline for sentiment analysis in Portuguese news using freely available resources and a minimal set of manually annotated training data. We obtained good precision o <a href=\"#\" onclick=\"$('#abstract_-BYWaAad9_').toggle();\">...</a>\n",
       "        <span id=\"abstract_-BYWaAad9_\" style=\"display:none\">n binary classification but concluded that news feed is a challenging environment to detect the extent of opinionated text.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/corpus-creation-and-analysis-for-named-entity\">Corpus Creation and Analysis for Named Entity Recognition in Telugu-English Code-Mixed Social Media Data</a> <small style=\"background: #eee\">0.982</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Entity Extraction using GAN, Named Entity Recognition\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Named Entity Recognition(NER) is one of the important tasks in Natural Language Processing(NLP) and also is a subtask of Information Extraction. In this paper we present our work on NER in Telugu-Engl <a href=\"#\" onclick=\"$('#abstract_93E5G2vdgS').toggle();\">...</a>\n",
       "        <span id=\"abstract_93E5G2vdgS\" style=\"display:none\">ish code-mixed social media data. Code-Mixing, a progeny of multilingualism is a way in which multilingual people express themselves on social media by using linguistics units from different languages within a sentence or speech context. Entity Extraction from social media data such as tweets(twitter) is in general difficult due to its informal nature, code-mixed data further complicates the problem due to its informal, unstructured and incomplete information. We present a Telugu-English code-mixed corpus with the corresponding named entity tags. The named entities used to tag data are Person({`}Per{'}), Organization({`}Org{'}) and Location({`}Loc{'}). We experimented with the machine learning models Conditional Random Fields(CRFs), Decision Trees and BiLSTMs on our corpus which resulted in a F1-score of 0.96, 0.94 and 0.95 respectively.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/an-arabic-tweets-sentiment-analysis-dataset\">An Arabic Tweets Sentiment Analysis Dataset (ATSAD) using Distant Supervision and Self Training</a> <small style=\"background: #eee\">0.988</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Arabic Sentiment Analysis, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        As the number of social media users increases, they express their thoughts, needs, socialise and publish their opinions reviews. For good social media sentiment analysis, good quality resources are ne <a href=\"#\" onclick=\"$('#abstract_RbMREVEWx_').toggle();\">...</a>\n",
       "        <span id=\"abstract_RbMREVEWx_\" style=\"display:none\">eded, and the lack of these resources is particularly evident for languages other than English, in particular Arabic. The available Arabic resources lack of from either the size of the corpus or the quality of the annotation. In this paper, we present an Arabic Sentiment Analysis Corpus collected from Twitter, which contains 36K tweets labelled into positive and negative. We employed distant supervision and self-training approaches into the corpus to annotate it. Besides, we release an 8K tweets manually annotated as a gold standard. We evaluated the corpus intrinsically by comparing it to human classification and pre-trained sentiment analysis models, Moreover, we apply extrinsic evaluation methods exploiting sentiment analysis task and achieve an accuracy of 86{\\%}.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/approaches-for-sentiment-analysis-on-twitter\">Approaches for Sentiment Analysis on Twitter: A State-of-Art study</a> <small style=\"background: #eee\">0.844</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Opinion Mining, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Microbloging is an extremely prevalent broadcast medium amidst the Internet\n",
       "fraternity these days. People share their opinions and sentiments about variety\n",
       "of subjects like products, news, institution <a href=\"#\" onclick=\"$('#abstract_MmkdpAqCLf').toggle();\">...</a>\n",
       "        <span id=\"abstract_MmkdpAqCLf\" style=\"display:none\">s, etc., every day on microbloging\n",
       "websites. Sentiment analysis plays a key role in prediction systems, opinion\n",
       "mining systems, etc. Twitter, one of the microbloging platforms allows a limit\n",
       "of 140 characters to its users. This restriction stimulates users to be very\n",
       "concise about their opinion and twitter an ocean of sentiments to analyze.\n",
       "Twitter also provides developer friendly streaming API for data retrieval\n",
       "purpose allowing the analyst to search real time tweets from various users. In\n",
       "this paper, we discuss the state-of-art of the works which are focused on\n",
       "Twitter, the online social network platform, for sentiment analysis. We survey\n",
       "various lexical, machine learning and hybrid approaches for sentiment analysis\n",
       "on Twitter.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/sentiment-analysis-for-low-resource-languages\">Sentiment Analysis for Low Resource Languages: A Study on Informal Indonesian Tweets</a> <small style=\"background: #eee\">0.991</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This paper describes our attempt to build a sentiment analysis system for Indonesian tweets. With this system, we can study and identify sentiments and opinions in a text or document computationally.  <a href=\"#\" onclick=\"$('#abstract_aEISsFBe_b').toggle();\">...</a>\n",
       "        <span id=\"abstract_aEISsFBe_b\" style=\"display:none\">We used four thousand manually labeled tweets collected in February and March 2016 to build the model. Because of the variety of content in tweets, we analyze tweets into eight groups in total, including pos(itive), neg(ative), and neu(tral). Finally, we obtained 73.2{\\%} accuracy with Long Short Term Memory (LSTM) without normalizer.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/an-empirical-study-of-discriminative-sequence\">An Empirical Study of Discriminative Sequence Labeling Models for Vietnamese Text Processing</a> <small style=\"background: #eee\">0.981</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Feature Engineering, Named Entity Recognition, Part-Of-Speech Tagging, Word Embeddings\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This paper presents an empirical study of two widely-used sequence prediction\n",
       "models, Conditional Random Fields (CRFs) and Long Short-Term Memory Networks\n",
       "(LSTMs), on two fundamental tasks for Vietnam <a href=\"#\" onclick=\"$('#abstract_f2CDXRDSTi').toggle();\">...</a>\n",
       "        <span id=\"abstract_f2CDXRDSTi\" style=\"display:none\">ese text processing, including\n",
       "part-of-speech tagging and named entity recognition. We show that a strong\n",
       "lower bound for labeling accuracy can be obtained by relying only on simple\n",
       "word-based features with minimal hand-crafted feature engineering, of 90.65\\%\n",
       "and 86.03\\% performance scores on the standard test sets for the two tasks\n",
       "respectively. In particular, we demonstrate empirically the surprising\n",
       "efficiency of word embeddings in both of the two tasks, with both of the two\n",
       "models. We point out that the state-of-the-art LSTMs model does not always\n",
       "outperform significantly the traditional CRFs model, especially on\n",
       "moderate-sized data sets. Finally, we give some suggestions and discussions for\n",
       "efficient use of sequence labeling models in practical applications.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/sentiment-analysis-for-hinglish-code-mixed\">Sentiment Analysis for Hinglish Code-mixed Tweets by means of Cross-lingual Word Embeddings</a> <small style=\"background: #eee\">0.987</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis, Transfer Learning, Word Embeddings\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This paper investigates the use of unsupervised cross-lingual embeddings for solving the problem of code-mixed social media text understanding. We specifically investigate the use of these embeddings  <a href=\"#\" onclick=\"$('#abstract_SFDN01nze-').toggle();\">...</a>\n",
       "        <span id=\"abstract_SFDN01nze-\" style=\"display:none\">for a sentiment analysis task for Hinglish Tweets, viz. English combined with (transliterated) Hindi. In a first step, baseline models, initialized with monolingual embeddings obtained from large collections of tweets in English and code-mixed Hinglish, were trained. In a second step, two systems using cross-lingual embeddings were researched, being (1) a supervised classifier and (2) a transfer learning approach trained on English sentiment data and evaluated on code-mixed data. We demonstrate that incorporating cross-lingual embeddings improves the results (F1-score of 0.635 versus a monolingual baseline of 0.616), without any parallel data required to train the cross-lingual embeddings. In addition, the results show that the cross-lingual embeddings not only improve the results in a fully supervised setting, but they can also be used as a base for distant supervision, by training a sentiment model in one of the source languages and evaluating on the other language projected in the same space. The transfer learning experiments result in an F1-score of 0.556, which is almost on par with the supervised settings and speak to the robustness of the cross-lingual embeddings approach.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/sentiment-analysis-for-modern-standard-arabic\">Sentiment Analysis For Modern Standard Arabic And Colloquial</a> <small style=\"background: #eee\">0.843</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Arabic Sentiment Analysis, Sentiment Analysis\n",
       "        <b>Methods:</b> SVM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The rise of social media such as blogs and social networks has fueled\n",
       "interest in sentiment analysis. With the proliferation of reviews, ratings,\n",
       "recommendations and other forms of online expression,  <a href=\"#\" onclick=\"$('#abstract_Pev5eDO2wd').toggle();\">...</a>\n",
       "        <span id=\"abstract_Pev5eDO2wd\" style=\"display:none\">online opinion has turned\n",
       "into a kind of virtual currency for businesses looking to market their\n",
       "products, identify new opportunities and manage their reputations, therefore\n",
       "many are now looking to the field of sentiment analysis. In this paper, we\n",
       "present a feature-based sentence level approach for Arabic sentiment analysis.\n",
       "Our approach is using Arabic idioms/saying phrases lexicon as a key importance\n",
       "for improving the detection of the sentiment polarity in Arabic sentences as\n",
       "well as a number of novels and rich set of linguistically motivated features\n",
       "contextual Intensifiers, contextual Shifter and negation handling), syntactic\n",
       "features for conflicting phrases which enhance the sentiment classification\n",
       "accuracy. Furthermore, we introduce an automatic expandable wide coverage\n",
       "polarity lexicon of Arabic sentiment words. The lexicon is built with\n",
       "gold-standard sentiment words as a seed which is manually collected and\n",
       "annotated and it expands and detects the sentiment orientation automatically of\n",
       "new sentiment words using synset aggregation technique and free online Arabic\n",
       "lexicons and thesauruses. Our data focus on modern standard Arabic (MSA) and\n",
       "Egyptian dialectal Arabic tweets and microblogs (hotel reservation, product\n",
       "reviews, etc.). The experimental results using our resources and techniques\n",
       "with SVM classifier indicate high performance levels, with accuracies of over\n",
       "95%.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/sentiment-analysis-using-collaborated-opinion\">Sentiment Analysis Using Collaborated Opinion Mining</a> <small style=\"background: #eee\">0.991</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Opinion Mining, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Opinion mining and Sentiment analysis have emerged as a field of study since\n",
       "the widespread of World Wide Web and internet. Opinion refers to extraction of\n",
       "those lines or phrase in the raw and huge da <a href=\"#\" onclick=\"$('#abstract_UI4ocjZ611').toggle();\">...</a>\n",
       "        <span id=\"abstract_UI4ocjZ611\" style=\"display:none\">ta which express an opinion.\n",
       "Sentiment analysis on the other hand identifies the polarity of the opinion\n",
       "being extracted. In this paper we propose the sentiment analysis in\n",
       "collaboration with opinion extraction, summarization, and tracking the records\n",
       "of the students. The paper modifies the existing algorithm in order to obtain\n",
       "the collaborated opinion about the students. The resultant opinion is\n",
       "represented as very high, high, moderate, low and very low. The paper is based\n",
       "on a case study where teachers give their remarks about the students and by\n",
       "applying the proposed sentiment analysis algorithm the opinion is extracted and\n",
       "represented.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/discourse-aware-rumour-stance-classification\">Discourse-Aware Rumour Stance Classification in Social Media Using Sequential Classifiers</a> <small style=\"background: #eee\">0.981</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Stance Classification\n",
       "        <b>Methods:</b> Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Rumour stance classification, defined as classifying the stance of specific\n",
       "social media posts into one of supporting, denying, querying or commenting on\n",
       "an earlier post, is becoming of increasing int <a href=\"#\" onclick=\"$('#abstract_I23woHjTDb').toggle();\">...</a>\n",
       "        <span id=\"abstract_I23woHjTDb\" style=\"display:none\">erest to researchers. While most\n",
       "previous work has focused on using individual tweets as classifier inputs, here\n",
       "we report on the performance of sequential classifiers that exploit the\n",
       "discourse features inherent in social media interactions or 'conversational\n",
       "threads'. Testing the effectiveness of four sequential classifiers -- Hawkes\n",
       "Processes, Linear-Chain Conditional Random Fields (Linear CRF), Tree-Structured\n",
       "Conditional Random Fields (Tree CRF) and Long Short Term Memory networks (LSTM)\n",
       "-- on eight datasets associated with breaking news stories, and looking at\n",
       "different types of local and contextual features, our work sheds new light on\n",
       "the development of accurate stance classifiers. We show that sequential\n",
       "classifiers that exploit the use of discourse properties in social media\n",
       "conversations while using only local features, outperform non-sequential\n",
       "classifiers. Furthermore, we show that LSTM using a reduced set of features can\n",
       "outperform the other sequential classifiers; this performance is consistent\n",
       "across datasets and across types of stances. To conclude, our work also\n",
       "analyses the different features under study, identifying those that best help\n",
       "characterise and distinguish between stances, such as supporting tweets being\n",
       "more likely to be accompanied by evidence than denying tweets. We also set\n",
       "forth a number of directions for future research.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/comparing-and-combining-sentiment-analysis\">Comparing and Combining Sentiment Analysis Methods</a> <small style=\"background: #eee\">0.987</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Several messages express opinions about events, products, and services,\n",
       "political views or even their author's emotional state and mood. Sentiment\n",
       "analysis has been used in several applications includ <a href=\"#\" onclick=\"$('#abstract_iL4vX9qe9_').toggle();\">...</a>\n",
       "        <span id=\"abstract_iL4vX9qe9_\" style=\"display:none\">ing analysis of the\n",
       "repercussions of events in social networks, analysis of opinions about products\n",
       "and services, and simply to better understand aspects of social communication\n",
       "in Online Social Networks (OSNs). There are multiple methods for measuring\n",
       "sentiments, including lexical-based approaches and supervised machine learning\n",
       "methods. Despite the wide use and popularity of some methods, it is unclear\n",
       "which method is better for identifying the polarity (i.e., positive or\n",
       "negative) of a message as the current literature does not provide a method of\n",
       "comparison among existing methods. Such a comparison is crucial for\n",
       "understanding the potential limitations, advantages, and disadvantages of\n",
       "popular methods in analyzing the content of OSNs messages. Our study aims at\n",
       "filling this gap by presenting comparisons of eight popular sentiment analysis\n",
       "methods in terms of coverage (i.e., the fraction of messages whose sentiment is\n",
       "identified) and agreement (i.e., the fraction of identified sentiments that are\n",
       "in tune with ground truth). We develop a new method that combines existing\n",
       "approaches, providing the best coverage results and competitive agreement. We\n",
       "also present a free Web service called iFeel, which provides an open API for\n",
       "accessing and comparing results across different sentiment methods for a given\n",
       "text.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "        <h3>Seed. <a href=\"https://paperswithcode.com/paper/fake-news-in-social-networks\">Fake News in Social Networks</a> <small style=\"background: #eee\">0.000</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We model the spread of news as a social learning game on a network. Agents\n",
       "can either endorse or oppose a claim made in a piece of news, which itself may\n",
       "be either true or false. Agents base their dec <a href=\"#\" onclick=\"$('#abstract_N0jcCtrbqO').toggle();\">...</a>\n",
       "        <span id=\"abstract_N0jcCtrbqO\" style=\"display:none\">ision on a private signal and\n",
       "their neighbors' past actions. Given these inputs, agents follow strategies\n",
       "derived via multi-agent deep reinforcement learning and receive utility from\n",
       "acting in accordance with the veracity of claims. Our framework yields\n",
       "strategies with agent utility close to a theoretical, Bayes optimal benchmark,\n",
       "while remaining flexible to model re-specification. Optimized strategies allow\n",
       "agents to correctly identify most false claims, when all agents receive\n",
       "unbiased private signals. However, an adversary's attempt to spread fake news\n",
       "by targeting a subset of agents with a biased private signal can be successful.\n",
       "Even more so when the adversary has information about agents' network position\n",
       "or private signal. When agents are aware of the presence of an adversary they\n",
       "re-optimize their strategies in the training stage and the adversary's attack\n",
       "is less effective. Hence, exposing agents to the possibility of fake news can\n",
       "be an effective way to curtail the spread of fake news in social networks. Our\n",
       "results also highlight that information about the users' private beliefs and\n",
       "their social network structure can be extremely valuable to adversaries and\n",
       "should be well protected.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "         <hr />\n",
       "    <table><thead><tr>\n",
       "    <th width=\"25%\">General purpose</th>\n",
       "    <th width=\"25%\">Task-related</th>\n",
       "    <th width=\"25%\">Method-related</th>\n",
       "    <th width=\"25%\">Dataset-related</th>\n",
       "    </thead><tbody>\n",
       "    <tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/lean-from-thy-neighbor-stochastic-adversarial\">Lean From Thy Neighbor: Stochastic & Adversarial Bandits in a Network</a> <small style=\"background: #eee\">0.791</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        An individual's decisions are often guided by those of his or her peers,\n",
       "i.e., neighbors in a social network. Presumably, being privy to the experiences\n",
       "of others aids in learning and decision making, <a href=\"#\" onclick=\"$('#abstract_1tv12AsETy').toggle();\">...</a>\n",
       "        <span id=\"abstract_1tv12AsETy\" style=\"display:none\"> but how much advantage does an\n",
       "individual gain by observing her neighbors? Such problems make appearances in\n",
       "sociology and economics and, in this paper, we present a novel model to capture\n",
       "such decision-making processes and appeal to the classical multi-armed bandit\n",
       "framework to analyze it. Each individual, in addition to her own actions, can\n",
       "observe the actions and rewards obtained by her neighbors, and can use all of\n",
       "this information in order to minimize her own regret. We provide algorithms for\n",
       "this setting, both for stochastic and adversarial bandits, and show that their\n",
       "regret smoothly interpolates between the regret in the classical bandit setting\n",
       "and that of the full-information setting as a function of the neighbors'\n",
       "exploration. In the stochastic setting the additional information must simply\n",
       "be incorporated into the usual estimation of the rewards, while in the\n",
       "adversarial setting this is attained by constructing a new unbiased estimator\n",
       "for the rewards and appropriately bounding the amount of additional information\n",
       "provided by the neighbors. These algorithms are optimal up to log factors;\n",
       "despite the fact that the agents act independently and selfishly, this implies\n",
       "that it is an approximate Nash equilibria for all agents to use our algorithms.\n",
       "Further, we show via empirical simulations that our algorithms, often\n",
       "significantly, outperform existing algorithms that one could apply to this\n",
       "setting.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/defending-against-neural-fake-news\">Defending Against Neural Fake News</a> <small style=\"background: #eee\">0.998</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Fake News Detection, Text Generation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> Grover-Mega\n",
       "        </p><p>\n",
       "        Recent progress in natural language generation has raised dual-use concerns. While applications like summarization and translation are positive, the underlying technology also might enable adversaries <a href=\"#\" onclick=\"$('#abstract_fe9ep0belm').toggle();\">...</a>\n",
       "        <span id=\"abstract_fe9ep0belm\" style=\"display:none\"> to generate neural fake news: targeted propaganda that closely mimics the style of real news. Modern computer security relies on careful threat modeling: identifying potential threats and vulnerabilities from an adversary's point of view, and exploring potential mitigations to these threats. Likewise, developing robust defenses against neural fake news requires us first to carefully investigate and characterize the risks of these models. We thus present a model for controllable text generation called Grover. Given a headline like `Link Found Between Vaccines and Autism,' Grover can generate the rest of the article; humans find these generations to be more trustworthy than human-written disinformation. Developing robust verification techniques against generators like Grover is critical. We find that best current discriminators can classify neural fake news from real, human-written, news with 73% accuracy, assuming access to a moderate level of training data. Counterintuitively, the best defense against Grover turns out to be Grover itself, with 92% accuracy, demonstrating the importance of public release of strong generators. We investigate these results further, showing that exposure bias -- and sampling strategies that alleviate its effects -- both leave artifacts that similar discriminators can pick up on. We conclude by discussing ethical issues regarding the technology, and plan to release Grover publicly, helping pave the way for better detection of neural fake news.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/sim-to-real-transfer-learning-using\">Sim-to-Real Transfer Learning using Robustified Controllers in Robotic Tasks involving Complex Dynamics</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Transfer Learning\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Learning robot tasks or controllers using deep reinforcement learning has\n",
       "been proven effective in simulations. Learning in simulation has several\n",
       "advantages. For example, one can fully control the si <a href=\"#\" onclick=\"$('#abstract_UiSSjpRXZd').toggle();\">...</a>\n",
       "        <span id=\"abstract_UiSSjpRXZd\" style=\"display:none\">mulated environment,\n",
       "including halting motions while performing computations. Another advantage when\n",
       "robots are involved, is that the amount of time a robot is occupied learning a\n",
       "task---rather than being productive---can be reduced by transferring the\n",
       "learned task to the real robot. Transfer learning requires some amount of\n",
       "fine-tuning on the real robot. For tasks which involve complex (non-linear)\n",
       "dynamics, the fine-tuning itself may take a substantial amount of time. In\n",
       "order to reduce the amount of fine-tuning we propose to learn robustified\n",
       "controllers in simulation. Robustified controllers are learned by exploiting\n",
       "the ability to change simulation parameters (both appearance and dynamics) for\n",
       "successive training episodes. An additional benefit for this approach is that\n",
       "it alleviates the precise determination of physics parameters for the\n",
       "simulator, which is a non-trivial task. We demonstrate our proposed approach on\n",
       "a real setup in which a robot aims to solve a maze game, which involves complex\n",
       "dynamics due to static friction and potentially large accelerations. We show\n",
       "that the amount of fine-tuning in transfer learning for a robustified\n",
       "controller is substantially reduced compared to a non-robustified controller.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/credulous-users-and-fake-news-a-real-case\">Credulous Users and Fake News: a Real Case Study on the Propagation in Twitter</a> <small style=\"background: #eee\">0.981</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Fake News Detection\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Recent studies have confirmed a growing trend, especially among youngsters, of using Online Social Media as favourite information platform at the expense of traditional mass media. Indeed, they can ea <a href=\"#\" onclick=\"$('#abstract_45aZWrcHjI').toggle();\">...</a>\n",
       "        <span id=\"abstract_45aZWrcHjI\" style=\"display:none\">sily reach a wide audience at a high speed; but exactly because of this they are the preferred medium for influencing public opinion via so-called fake news. Moreover, there is a general agreement that the main vehicle of fakes news are malicious software robots (bots) that automatically interact with human users. In previous work we have considered the problem of tagging human users in Online Social Networks as credulous users. Specifically, we have considered credulous those users with relatively high number of bot friends when compared to total number of their social friends. We consider this group of users worth of attention because they might have a higher exposure to malicious activities and they may contribute to the spreading of fake information by sharing dubious content. In this work, starting from a dataset of fake news, we investigate the behaviour and the degree of involvement of credulous users in fake news diffusion. The study aims to: (i) fight fake news by considering the content diffused by credulous users; (ii) highlight the relationship between credulous users and fake news spreading; (iii) target fake news detection by focusing on the analysis of specific accounts more exposed to malicious activities of bots. Our first results demonstrate a strong involvement of credulous users in fake news diffusion. This findings are calling for tools that, by performing data streaming on credulous' users actions, enables us to perform targeted fact-checking.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/incentivizing-exploration-with-unbiased\">Incentivizing Exploration with Selective Data Disclosure</a> <small style=\"background: #eee\">0.789</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We study the design of rating systems that incentivize (more) efficient social learning among self-interested agents. Agents arrive sequentially and are presented with a set of possible actions, each  <a href=\"#\" onclick=\"$('#abstract_tVsp5KR4hQ').toggle();\">...</a>\n",
       "        <span id=\"abstract_tVsp5KR4hQ\" style=\"display:none\">of which yields a positive reward with an unknown probability. A disclosure policy sends messages about the rewards of previously-chosen actions to arriving agents. These messages can alter agents' incentives towards exploration, taking potentially sub-optimal actions for the sake of learning more about their rewards. Prior work achieves much progress with disclosure policies that merely recommend an action to each user, but relies heavily on standard, yet very strong rationality assumptions. We study a particular class of disclosure policies that use messages, called unbiased subhistories, consisting of the actions and rewards from a subsequence of past agents. Each subsequence is chosen ahead of time, according to a predetermined partial order on the rounds. We posit a flexible model of frequentist agent response, which we argue is plausible for this class of \"order-based\" disclosure policies. We measure the success of a policy by its regret, i.e., the difference, over all rounds, between the expected reward of the best action and the reward induced by the policy. A disclosure policy that reveals full history in each round risks inducing herding behavior among the agents, and typically has regret linear in the time horizon $T$. Our main result is an order-based disclosure policy that obtains regret $\\tilde{O}(\\sqrt{T})$. This regret is known to be optimal in the worst case over reward distributions, even absent incentives. We also exhibit simpler order-based policies with higher, but still sublinear, regret. These policies can be interpreted as dividing a sublinear number of agents into constant-sized focus groups, whose histories are then revealed to future agents.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/dehide-deep-learning-based-hybrid-model-to\">DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain</a> <small style=\"background: #eee\">0.997</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The surge in the spread of misleading information, lies, propaganda, and false facts, frequently known as fake news, raised questions concerning social media's influence in today's fast-moving democra <a href=\"#\" onclick=\"$('#abstract_ZFZ2JSRLVI').toggle();\">...</a>\n",
       "        <span id=\"abstract_ZFZ2JSRLVI\" style=\"display:none\">tic society. The widespread and rapid dissemination of fake news cost us in many ways. For example, individual or societal costs by hampering elections integrity, significant economic losses by impacting stock markets, or increases the risk to national security. It is challenging to overcome the spreading of fake news problems in traditional centralized systems. However, Blockchain-- a distributed decentralized technology that ensures data provenance, authenticity, and traceability by providing a transparent, immutable, and verifiable transaction records can help in detecting and contending fake news. This paper proposes a novel hybrid model DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain. The DeHiDe is a blockchain-based framework for legitimate news sharing by filtering out the fake news. It combines the benefit of blockchain with an intelligent deep learning model to reinforce robustness and accuracy in combating fake news's hurdle. It also compares the proposed method to existing state-of-the-art methods. The DeHiDe is expected to outperform state-of-the-art approaches in terms of services, features, and performance.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/robust-recovery-controller-for-a-quadrupedal\">Robust Recovery Controller for a Quadrupedal Robot using Deep Reinforcement Learning</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The ability to recover from a fall is an essential feature for a legged robot\n",
       "to navigate in challenging environments robustly. Until today, there has been\n",
       "very little progress on this topic. Current  <a href=\"#\" onclick=\"$('#abstract_7bu6W5YkTr').toggle();\">...</a>\n",
       "        <span id=\"abstract_7bu6W5YkTr\" style=\"display:none\">solutions mostly build upon\n",
       "(heuristically) predefined trajectories, resulting in unnatural behaviors and\n",
       "requiring considerable effort in engineering system-specific components. In\n",
       "this paper, we present an approach based on model-free Deep Reinforcement\n",
       "Learning (RL) to control recovery maneuvers of quadrupedal robots using a\n",
       "hierarchical behavior-based controller. The controller consists of four neural\n",
       "network policies including three behaviors and one behavior selector to\n",
       "coordinate them. Each of them is trained individually in simulation and\n",
       "deployed directly on a real system. We experimentally validate our approach on\n",
       "the quadrupedal robot ANYmal, which is a dog-sized quadrupedal system with 12\n",
       "degrees of freedom. With our method, ANYmal manifests dynamic and reactive\n",
       "recovery behaviors to recover from an arbitrary fall configuration within less\n",
       "than 5 seconds. We tested the recovery maneuver more than 100 times, and the\n",
       "success rate was higher than 97 %.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/where-are-the-facts-searching-for-fact\">Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News</a> <small style=\"background: #eee\">0.980</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Ad-Hoc Information Retrieval, Fact Verification, Fake News Detection, Image Matting, misinformation, Text Matching\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Although many fact-checking systems have been developed in academia and industry, fake news is still proliferating on social media. These systems mostly focus on fact-checking but usually neglect onli <a href=\"#\" onclick=\"$('#abstract_tc7b1aHpcw').toggle();\">...</a>\n",
       "        <span id=\"abstract_tc7b1aHpcw\" style=\"display:none\">ne users who are the main drivers of the spread of misinformation. How can we use fact-checked information to improve users' consciousness of fake news to which they are exposed? How can we stop users from spreading fake news? To tackle these questions, we propose a novel framework to search for fact-checking articles, which address the content of an original tweet (that may contain misinformation) posted by online users. The search can directly warn fake news posters and online users (e.g. the posters' followers) about misinformation, discourage them from spreading fake news, and scale up verified content on social media. Our framework uses both text and images to search for fact-checking articles, and achieves promising results on real-world datasets. Our code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/online-discrete-optimization-in-social\">Online discrete optimization in social networks in the presence of Knightian uncertainty</a> <small style=\"background: #eee\">0.786</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We study a model of collective real-time decision-making (or learning) in a\n",
       "social network operating in an uncertain environment, for which no a priori\n",
       "probabilistic model is available. Instead, the e <a href=\"#\" onclick=\"$('#abstract_UeBTIH2Snm').toggle();\">...</a>\n",
       "        <span id=\"abstract_UeBTIH2Snm\" style=\"display:none\">nvironment's impact on the\n",
       "agents in the network is seen through a sequence of cost functions, revealed to\n",
       "the agents in a causal manner only after all the relevant actions are taken.\n",
       "There are two kinds of costs: individual costs incurred by each agent and\n",
       "local-interaction costs incurred by each agent and its neighbors in the social\n",
       "network. Moreover, agents have inertia: each agent has a default mixed strategy\n",
       "that stays fixed regardless of the state of the environment, and must expend\n",
       "effort to deviate from this strategy in order to respond to cost signals coming\n",
       "from the environment. We construct a decentralized strategy, wherein each agent\n",
       "selects its action based only on the costs directly affecting it and on the\n",
       "decisions made by its neighbors in the network. In this setting, we quantify\n",
       "social learning in terms of regret, which is given by the difference between\n",
       "the realized network performance over a given time horizon and the best\n",
       "performance that could have been achieved in hindsight by a fictitious\n",
       "centralized entity with full knowledge of the environment's evolution. We show\n",
       "that our strategy achieves the regret that scales polylogarithmically with the\n",
       "time horizon and polynomially with the number of agents and the maximum number\n",
       "of neighbors of any agent in the social network.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/news-labeling-as-early-as-possible-real-or\">News Labeling as Early as Possible: Real or Fake?</a> <small style=\"background: #eee\">0.997</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Making disguise between real and fake news propagation through online social networks is an important issue in many applications. The time gap between the news release time and detection of its label  <a href=\"#\" onclick=\"$('#abstract_eaYpVF2HWu').toggle();\">...</a>\n",
       "        <span id=\"abstract_eaYpVF2HWu\" style=\"display:none\">is a significant step towards broadcasting the real information and avoiding the fake. Therefore, one of the challenging tasks in this area is to identify fake and real news in early stages of propagation. However, there is a trade-off between minimizing the time gap and maximizing accuracy. Despite recent efforts in detection of fake news, there has been no significant work that explicitly incorporates early detection in its model. In this paper, we focus on accurate early labeling of news, and propose a model by considering earliness both in modeling and prediction. The proposed method utilizes recurrent neural networks with a novel loss function, and a new stopping rule. Given the context of news, we first embed it with a class-specific text representation. Then, we utilize the available public profile of users, and speed of news diffusion, for early labeling of the news. Experiments on real datasets demonstrate the effectiveness of our model both in terms of early labelling and accuracy, compared to the state of the art baseline and models.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/acceleration-of-actor-critic-deep\">Acceleration of Actor-Critic Deep Reinforcement Learning for Visual Grasping in Clutter by State Representation Learning Based on Disentanglement of a Raw Input Image</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Representation Learning, Robotic Grasping\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        For a robotic grasping task in which diverse unseen target objects exist in a cluttered environment, some deep learning-based methods have achieved state-of-the-art results using visual input directly <a href=\"#\" onclick=\"$('#abstract_EqGboVRy2q').toggle();\">...</a>\n",
       "        <span id=\"abstract_EqGboVRy2q\" style=\"display:none\">. In contrast, actor-critic deep reinforcement learning (RL) methods typically perform very poorly when grasping diverse objects, especially when learning from raw images and sparse rewards. To make these RL techniques feasible for vision-based grasping tasks, we employ state representation learning (SRL), where we encode essential information first for subsequent use in RL. However, typical representation learning procedures are unsuitable for extracting pertinent information for learning the grasping skill, because the visual inputs for representation learning, where a robot attempts to grasp a target object in clutter, are extremely complex. We found that preprocessing based on the disentanglement of a raw input image is the key to effectively capturing a compact representation. This enables deep RL to learn robotic grasping skills from highly varied and diverse visual inputs. We demonstrate the effectiveness of this approach with varying levels of disentanglement in a realistic simulated environment.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/balancing-information-exposure-in-social\">Balancing information exposure in social networks</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Social media has brought a revolution on how people are consuming news. Beyond the undoubtedly large number of advantages brought by social-media platforms, a point of criticism has been the creation  <a href=\"#\" onclick=\"$('#abstract_bUVRo65z6f').toggle();\">...</a>\n",
       "        <span id=\"abstract_bUVRo65z6f\" style=\"display:none\">of echo chambers and filter bubbles, caused by social homophily and algorithmic personalization.  In this paper we address the problem of balancing the information exposure} in a social network. We assume that two opposing campaigns (or viewpoints) are present in the network, and that network nodes have different preferences towards these campaigns. Our goal is to find two sets of nodes to employ in the respective campaigns, so that the overall information exposure for the two campaigns is balanced. We formally define the problem, characterize its hardness, develop approximation algorithms, and present experimental evaluation results.  Our model is inspired by the literature on influence maximization, but we offer significant novelties. First, balance of information exposure is modeled by a symmetric difference function, which is neither monotone nor submodular, and thus, not amenable to existing approaches. Second, while previous papers consider a setting with selfish agents and provide bounds on best response strategies (i.e., move of the last player), we consider a setting with a centralized agent and provide bounds for a global objective function.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/beliefs-in-decision-making-cascades\">Beliefs in Decision-Making Cascades</a> <small style=\"background: #eee\">0.785</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This work explores a social learning problem with agents having nonidentical noise variances and mismatched beliefs. We consider an $N$-agent binary hypothesis test in which each agent sequentially ma <a href=\"#\" onclick=\"$('#abstract_sIfz5V0uS3').toggle();\">...</a>\n",
       "        <span id=\"abstract_sIfz5V0uS3\" style=\"display:none\">kes a decision based not only on a private observation, but also on preceding agents' decisions. In addition, the agents have their own beliefs instead of the true prior, and have nonidentical noise variances in the private signal. We focus on the Bayes risk of the last agent, where preceding agents are selfish. We first derive the optimal decision rule by recursive belief update and conclude, counterintuitively, that beliefs deviating from the true prior could be optimal in this setting. The effect of nonidentical noise levels in the two-agent case is also considered and analytical properties of the optimal belief curves are given. Next, we consider a predecessor selection problem wherein the subsequent agent of a certain belief chooses a predecessor from a set of candidates with varying beliefs. We characterize the decision region for choosing such a predecessor and argue that a subsequent agent with beliefs varying from the true prior often ends up selecting a suboptimal predecessor, indicating the need for a social planner. Lastly, we discuss an augmented intelligence design problem that uses a model of human behavior from cumulative prospect theory and investigate its near-optimality and suboptimality.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/credulous-users-and-fake-news-a-real-case\">Credulous Users and Fake News: a Real Case Study on the Propagation in Twitter</a> <small style=\"background: #eee\">0.997</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Fake News Detection\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Recent studies have confirmed a growing trend, especially among youngsters, of using Online Social Media as favourite information platform at the expense of traditional mass media. Indeed, they can ea <a href=\"#\" onclick=\"$('#abstract_45aZWrcHjI').toggle();\">...</a>\n",
       "        <span id=\"abstract_45aZWrcHjI\" style=\"display:none\">sily reach a wide audience at a high speed; but exactly because of this they are the preferred medium for influencing public opinion via so-called fake news. Moreover, there is a general agreement that the main vehicle of fakes news are malicious software robots (bots) that automatically interact with human users. In previous work we have considered the problem of tagging human users in Online Social Networks as credulous users. Specifically, we have considered credulous those users with relatively high number of bot friends when compared to total number of their social friends. We consider this group of users worth of attention because they might have a higher exposure to malicious activities and they may contribute to the spreading of fake information by sharing dubious content. In this work, starting from a dataset of fake news, we investigate the behaviour and the degree of involvement of credulous users in fake news diffusion. The study aims to: (i) fight fake news by considering the content diffused by credulous users; (ii) highlight the relationship between credulous users and fake news spreading; (iii) target fake news detection by focusing on the analysis of specific accounts more exposed to malicious activities of bots. Our first results demonstrate a strong involvement of credulous users in fake news diffusion. This findings are calling for tools that, by performing data streaming on credulous' users actions, enables us to perform targeted fact-checking.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/forecaster-a-continual-lifelong-learning\">FORECASTER: A Continual Lifelong Learning Approach to Improve Hardware Efficiency</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Computer applications are continuously evolving. However, significant knowledge can be harvested from older applications or versions and applied in the context of newer applications or versions. Such  <a href=\"#\" onclick=\"$('#abstract_fsYpMNty-I').toggle();\">...</a>\n",
       "        <span id=\"abstract_fsYpMNty-I\" style=\"display:none\">a vision can be realized with Continual Lifelong Learning. Therefore, we propose to employ continual lifelong learning to dynamically tune hardware configurations based on application behavior. The goal of such tuning is to maximize hardware efficiency (i.e., maximize an application performance while minimizing the hardware energy consumption). Our proposed approach, FORECASTER, uses deep reinforcement learning to continually learn during the execution of an application as well as propagate and utilize the accumulated knowledge during subsequent executions of the same or new application. We propose a novel hardware and ISA support to implement deep reinforcement learning. We implement FORECASTER and compare its performance against prior learning-based hardware reconfiguration approaches. Our results show that FORECASTER can save an average 16% of system power over the baseline setup with full usage of hardware while sacrificing an average of 4.7% of execution time.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/leveraging-the-crowd-to-detect-and-reduce-the\">Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation</a> <small style=\"background: #eee\">0.978</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> misinformation, Point Processes\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Online social networking sites are experimenting with the following\n",
       "crowd-powered procedure to reduce the spread of fake news and misinformation:\n",
       "whenever a user is exposed to a story through her feed <a href=\"#\" onclick=\"$('#abstract_wZHtEtEg_0').toggle();\">...</a>\n",
       "        <span id=\"abstract_wZHtEtEg_0\" style=\"display:none\">, she can flag the story\n",
       "as misinformation and, if the story receives enough flags, it is sent to a\n",
       "trusted third party for fact checking. If this party identifies the story as\n",
       "misinformation, it is marked as disputed. However, given the uncertain number\n",
       "of exposures, the high cost of fact checking, and the trade-off between flags\n",
       "and exposures, the above mentioned procedure requires careful reasoning and\n",
       "smart algorithms which, to the best of our knowledge, do not exist to date.\n",
       "  In this paper, we first introduce a flexible representation of the above\n",
       "procedure using the framework of marked temporal point processes. Then, we\n",
       "develop a scalable online algorithm, Curb, to select which stories to send for\n",
       "fact checking and when to do so to efficiently reduce the spread of\n",
       "misinformation with provable guarantees. In doing so, we need to solve a novel\n",
       "stochastic optimal control problem for stochastic differential equations with\n",
       "jumps, which is of independent interest. Experiments on two real-world datasets\n",
       "gathered from Twitter and Weibo show that our algorithm may be able to\n",
       "effectively reduce the spread of fake news and misinformation.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/learning-without-recall-by-random-walks-on\">Learning without Recall by Random Walks on Directed Graphs</a> <small style=\"background: #eee\">0.783</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Bayesian Inference\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We consider a network of agents that aim to learn some unknown state of the\n",
       "world using private observations and exchange of beliefs. At each time, agents\n",
       "observe private signals generated based on th <a href=\"#\" onclick=\"$('#abstract_RCVYCFydVL').toggle();\">...</a>\n",
       "        <span id=\"abstract_RCVYCFydVL\" style=\"display:none\">e true unknown state. Each agent\n",
       "might not be able to distinguish the true state based only on her private\n",
       "observations. This occurs when some other states are observationally equivalent\n",
       "to the true state from the agent's perspective. To overcome this shortcoming,\n",
       "agents must communicate with each other to benefit from local observations. We\n",
       "propose a model where each agent selects one of her neighbors randomly at each\n",
       "time. Then, she refines her opinion using her private signal and the prior of\n",
       "that particular neighbor. The proposed rule can be thought of as a Bayesian\n",
       "agent who cannot recall the priors based on which other agents make inferences.\n",
       "This learning without recall approach preserves some aspects of the Bayesian\n",
       "inference while being computationally tractable. By establishing a\n",
       "correspondence with a random walk on the network graph, we prove that under the\n",
       "described protocol, agents learn the truth exponentially fast in the almost\n",
       "sure sense. The asymptotic rate is expressed as the sum of the relative\n",
       "entropies between the signal structures of every agent weighted by the\n",
       "stationary distribution of the random walk.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/attributed-multi-relational-attention-network\">Attributed Multi-Relational Attention Network for Fact-checking URL Recommendation</a> <small style=\"background: #eee\">0.997</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Recommendation Systems\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        To combat fake news, researchers mostly focused on detecting fake news and journalists built and maintained fact-checking sites (e.g., Snopes.com and Politifact.com). However, fake news dissemination  <a href=\"#\" onclick=\"$('#abstract_O5zHowOFi0').toggle();\">...</a>\n",
       "        <span id=\"abstract_O5zHowOFi0\" style=\"display:none\">has been greatly promoted via social media sites, and these fact-checking sites have not been fully utilized. To overcome these problems and complement existing methods against fake news, in this paper we propose a deep-learning based fact-checking URL recommender system to mitigate impact of fake news in social media sites such as Twitter and Facebook. In particular, our proposed framework consists of a multi-relational attentive module and a heterogeneous graph attention network to learn complex/semantic relationship between user-URL pairs, user-user pairs, and URL-URL pairs. Extensive experiments on a real-world dataset show that our proposed framework outperforms eight state-of-the-art recommendation models, achieving at least 3~5.3% improvement.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/continuous-state-space-models-for-optimal\">Continuous State-Space Models for Optimal Sepsis Treatment - a Deep Reinforcement Learning Approach</a> <small style=\"background: #eee\">0.985</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Sepsis is a leading cause of mortality in intensive care units (ICUs) and\n",
       "costs hospitals billions annually. Treating a septic patient is highly\n",
       "challenging, because individual patients respond very d <a href=\"#\" onclick=\"$('#abstract_FHCQBZnvQD').toggle();\">...</a>\n",
       "        <span id=\"abstract_FHCQBZnvQD\" style=\"display:none\">ifferently to medical\n",
       "interventions and there is no universally agreed-upon treatment for sepsis.\n",
       "Understanding more about a patient's physiological state at a given time could\n",
       "hold the key to effective treatment policies. In this work, we propose a new\n",
       "approach to deduce optimal treatment policies for septic patients by using\n",
       "continuous state-space models and deep reinforcement learning. Learning\n",
       "treatment policies over continuous spaces is important, because we retain more\n",
       "of the patient's physiological information. Our model is able to learn\n",
       "clinically interpretable treatment policies, similar in important aspects to\n",
       "the treatment policies of physicians. Evaluating our algorithm on past ICU\n",
       "patient data, we find that our model could reduce patient mortality in the\n",
       "hospital by up to 3.6% over observed clinical policies, from a baseline\n",
       "mortality of 13.7%. The learned treatment policies could be used to aid\n",
       "intensive care clinicians in medical decision making and improve the likelihood\n",
       "of patient survival.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/online-learning-and-optimization-under-a-new\">Online Learning and Optimization Under a New Linear-Threshold Model with Negative Influence</a> <small style=\"background: #eee\">0.976</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We propose a new class of Linear Threshold Model-based information-diffusion model that incorporates the formation and spread of negative attitude. We call such models negativity-aware.. We show that  <a href=\"#\" onclick=\"$('#abstract_G6KIkrkeLK').toggle();\">...</a>\n",
       "        <span id=\"abstract_G6KIkrkeLK\" style=\"display:none\">in these models, the influence function is a monotone submodular function. Thus we can use the greedy algorithm to construct seed sets with constant approximation guarantees, when the objective is to select a seed set of fixed size $K$ to maximize total influence. Our models are flexible enough to account for both the features of local users and the features of the information being propagated in the diffusion. We analyze an online-learning setting for a multi-round influence-maximization problem, where an agent is actively learning the diffusion parameters over time while trying to maximize total cumulative positive influence. We assume that in each diffusion step, the agent can only observe whether a node becomes positively or negatively influenced, or remains inactive. In particular, he does not observe the particular edge that brought about the activation of a node, if any, as in the case of most models that assume Independent Cascade (IC)-based diffusions. This model of feedback is called node-level feedback, as opposed to the more common \\emph{edge-level feedback} model in which he is able to observe, for each node, the edge through which that node is influenced. Under mild assumptions, we develop online learning algorithms that achieve cumulative expected regrets of order $O(T^{-c})$ for any $c<1$ where $T$ is the total number of rounds. These are the first regret guarantees for node-level feedback models of influence maximization of any kind. Furthermore, with mild assumptions, this result also improves the average regret of $O(\\sqrt{\\ln T / T})$ for the edge-level feedback models, thus providing a new performance benchmark.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pid in sample_ids:\n",
    "    display(HTML(get_multi_view_html(pid, show_details=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "        <h3>Seed. <a href=\"https://paperswithcode.com/paper/predicting-distresses-using-deep-learning-of\">Predicting Distresses using Deep Learning of Text Segments in Annual Reports</a> <small style=\"background: #eee\">0.000</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Corporate distress models typically only employ the numerical financial\n",
       "variables in the firms' annual reports. We develop a model that employs the\n",
       "unstructured textual data in the reports as well, na <a href=\"#\" onclick=\"$('#abstract_9ac52Illrt').toggle();\">...</a>\n",
       "        <span id=\"abstract_9ac52Illrt\" style=\"display:none\">mely the auditors' reports\n",
       "and managements' statements. Our model consists of a convolutional recurrent\n",
       "neural network which, when concatenated with the numerical financial variables,\n",
       "learns a descriptive representation of the text that is suited for corporate\n",
       "distress prediction. We find that the unstructured data provides a\n",
       "statistically significant enhancement of the distress prediction performance,\n",
       "in particular for large firms where accurate predictions are of the utmost\n",
       "importance. Furthermore, we find that auditors' reports are more informative\n",
       "than managements' statements and that a joint model including both managements'\n",
       "statements and auditors' reports displays no enhancement relative to a model\n",
       "including only auditors' reports. Our model demonstrates a direct improvement\n",
       "over existing state-of-the-art models.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "         <hr />\n",
       "    <table><thead><tr>\n",
       "    <th width=\"25%\">General purpose</th>\n",
       "    <th width=\"25%\">Task-related</th>\n",
       "    <th width=\"25%\">Method-related</th>\n",
       "    <th width=\"25%\">Dataset-related</th>\n",
       "    </thead><tbody>\n",
       "    <tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/bank-distress-in-the-news-describing-events\">Bank distress in the news: Describing events through deep learning</a> <small style=\"background: #eee\">0.792</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        While many models are purposed for detecting the occurrence of significant\n",
       "events in financial systems, the task of providing qualitative detail on the\n",
       "developments is not usually as well automated. W <a href=\"#\" onclick=\"$('#abstract_tMNINWILd7').toggle();\">...</a>\n",
       "        <span id=\"abstract_tMNINWILd7\" style=\"display:none\">e present a deep learning\n",
       "approach for detecting relevant discussion in text and extracting natural\n",
       "language descriptions of events. Supervised by only a small set of event\n",
       "information, comprising entity names and dates, the model is leveraged by\n",
       "unsupervised learning of semantic vector representations on extensive text\n",
       "data. We demonstrate applicability to the study of financial risk based on news\n",
       "(6.6M articles), particularly bank distress and government interventions (243\n",
       "events), where indices can signal the level of bank-stress-related reporting at\n",
       "the entity level, or aggregated at national or European level, while being\n",
       "coupled with explanations. Thus, we exemplify how text, as timely, widely\n",
       "available and descriptive data, can serve as a useful complementary source of\n",
       "information for financial and systemic risk analytics.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/bank-distress-in-the-news-describing-events\">Bank distress in the news: Describing events through deep learning</a> <small style=\"background: #eee\">0.982</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        While many models are purposed for detecting the occurrence of significant\n",
       "events in financial systems, the task of providing qualitative detail on the\n",
       "developments is not usually as well automated. W <a href=\"#\" onclick=\"$('#abstract_tMNINWILd7').toggle();\">...</a>\n",
       "        <span id=\"abstract_tMNINWILd7\" style=\"display:none\">e present a deep learning\n",
       "approach for detecting relevant discussion in text and extracting natural\n",
       "language descriptions of events. Supervised by only a small set of event\n",
       "information, comprising entity names and dates, the model is leveraged by\n",
       "unsupervised learning of semantic vector representations on extensive text\n",
       "data. We demonstrate applicability to the study of financial risk based on news\n",
       "(6.6M articles), particularly bank distress and government interventions (243\n",
       "events), where indices can signal the level of bank-stress-related reporting at\n",
       "the entity level, or aggregated at national or European level, while being\n",
       "coupled with explanations. Thus, we exemplify how text, as timely, widely\n",
       "available and descriptive data, can serve as a useful complementary source of\n",
       "information for financial and systemic risk analytics.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/jointly-learning-to-detect-emotions-and\">Jointly Learning to Detect Emotions and Predict Facebook Reactions</a> <small style=\"background: #eee\">0.978</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Emotion Classification\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The growing ubiquity of Social Media data offers an attractive perspective for improving the quality of machine learning-based models in several fields, ranging from Computer Vision to Natural Languag <a href=\"#\" onclick=\"$('#abstract__M-qVVkni-').toggle();\">...</a>\n",
       "        <span id=\"abstract__M-qVVkni-\" style=\"display:none\">e Processing. In this paper we focus on Facebook posts paired with reactions of multiple users, and we investigate their relationships with classes of emotions that are typically considered in the task of emotion detection. We are inspired by the idea of introducing a connection between reactions and emotions by means of First-Order Logic formulas, and we propose an end-to-end neural model that is able to jointly learn to detect emotions and predict Facebook reactions in a multi-task environment, where the logic formulas are converted into polynomial constraints. Our model is trained using a large collection of unsupervised texts together with data labeled with emotion classes and Facebook posts that include reactions. An extended experimental analysis that leverages a large collection of Facebook posts shows that the tasks of emotion classification and reaction prediction can both benefit from their interaction.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/deep-learning-bank-distress-from-news-and\">Deep learning bank distress from news and numerical financial data</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        In this paper we focus our attention on the exploitation of the information\n",
       "contained in financial news to enhance the performance of a classifier of bank\n",
       "distress. Such information should be analyzed <a href=\"#\" onclick=\"$('#abstract_-TQl6tgFCc').toggle();\">...</a>\n",
       "        <span id=\"abstract_-TQl6tgFCc\" style=\"display:none\"> and inserted into the predictive\n",
       "model in the most efficient way and this task deals with all the issues related\n",
       "to text analysis and specifically analysis of news media. Among the different\n",
       "models proposed for such purpose, we investigate one of the possible deep\n",
       "learning approaches, based on a doc2vec representation of the textual data, a\n",
       "kind of neural network able to map the sequential and symbolic text input onto\n",
       "a reduced latent semantic space. Afterwards, a second supervised neural network\n",
       "is trained combining news data with standard financial figures to classify\n",
       "banks whether in distressed or tranquil states, based on a small set of known\n",
       "distress events. Then the final aim is not only the improvement of the\n",
       "predictive performance of the classifier but also to assess the importance of\n",
       "news data in the classification process. Does news data really bring more\n",
       "useful information not contained in standard financial variables? Our results\n",
       "seem to confirm such hypothesis.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/deep-learning-bank-distress-from-news-and\">Deep learning bank distress from news and numerical financial data</a> <small style=\"background: #eee\">0.790</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        In this paper we focus our attention on the exploitation of the information\n",
       "contained in financial news to enhance the performance of a classifier of bank\n",
       "distress. Such information should be analyzed <a href=\"#\" onclick=\"$('#abstract_-TQl6tgFCc').toggle();\">...</a>\n",
       "        <span id=\"abstract_-TQl6tgFCc\" style=\"display:none\"> and inserted into the predictive\n",
       "model in the most efficient way and this task deals with all the issues related\n",
       "to text analysis and specifically analysis of news media. Among the different\n",
       "models proposed for such purpose, we investigate one of the possible deep\n",
       "learning approaches, based on a doc2vec representation of the textual data, a\n",
       "kind of neural network able to map the sequential and symbolic text input onto\n",
       "a reduced latent semantic space. Afterwards, a second supervised neural network\n",
       "is trained combining news data with standard financial figures to classify\n",
       "banks whether in distressed or tranquil states, based on a small set of known\n",
       "distress events. Then the final aim is not only the improvement of the\n",
       "predictive performance of the classifier but also to assess the importance of\n",
       "news data in the classification process. Does news data really bring more\n",
       "useful information not contained in standard financial variables? Our results\n",
       "seem to confirm such hypothesis.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/firms-default-prediction-with-machine\">Firms Default Prediction with Machine Learning</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Academics and practitioners have studied over the years models for predicting firms bankruptcy, using statistical and machine-learning approaches. An earlier sign that a company has financial difficul <a href=\"#\" onclick=\"$('#abstract_TxuUWnrZy-').toggle();\">...</a>\n",
       "        <span id=\"abstract_TxuUWnrZy-\" style=\"display:none\">ties and may eventually bankrupt is going in \\emph{default}, which, loosely speaking means that the company has been having difficulties in repaying its loans towards the banking system. Firms default status is not technically a failure but is very relevant for bank lending policies and often anticipates the failure of the company. Our study uses, for the first time according to our knowledge, a very large database of granular credit data from the Italian Central Credit Register of Bank of Italy that contain information on all Italian companies' past behavior towards the entire Italian banking system to predict their default using machine-learning techniques. Furthermore, we combine these data with other information regarding companies' public balance sheet data. We find that ensemble techniques and random forest provide the best results, corroborating the findings of Barboza et al. (Expert Syst. Appl., 2017).</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/multimodal-sentiment-analysis-to-explore-the\">Multimodal Sentiment Analysis To Explore the Structure of Emotions</a> <small style=\"background: #eee\">0.978</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Multimodal Sentiment Analysis, Sentiment Analysis\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We propose a novel approach to multimodal sentiment analysis using deep\n",
       "neural networks combining visual analysis and natural language processing. Our\n",
       "goal is different than the standard sentiment ana <a href=\"#\" onclick=\"$('#abstract_DAXwmyeSx_').toggle();\">...</a>\n",
       "        <span id=\"abstract_DAXwmyeSx_\" style=\"display:none\">lysis goal of predicting\n",
       "whether a sentence expresses positive or negative sentiment; instead, we aim to\n",
       "infer the latent emotional state of the user. Thus, we focus on predicting the\n",
       "emotion word tags attached by users to their Tumblr posts, treating these as\n",
       "\"self-reported emotions.\" We demonstrate that our multimodal model combining\n",
       "both text and image features outperforms separate models based solely on either\n",
       "images or text. Our model's results are interpretable, automatically yielding\n",
       "sensible word lists associated with emotions. We explore the structure of\n",
       "emotions implied by our model and compare it to what has been posited in the\n",
       "psychology literature, and validate our model on a set of images that have been\n",
       "used in psychology studies. Finally, our work also provides a useful tool for\n",
       "the growing academic study of images - both photographs and memes - on social\n",
       "networks.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/detect-describe-deep-learning-of-bank-stress\">Detect & Describe: Deep learning of bank stress in the news</a> <small style=\"background: #eee\">0.969</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        News is a pertinent source of information on financial risks and stress\n",
       "factors, which nevertheless is challenging to harness due to the sparse and\n",
       "unstructured nature of natural text. We propose an a <a href=\"#\" onclick=\"$('#abstract_MxQcgofjz9').toggle();\">...</a>\n",
       "        <span id=\"abstract_MxQcgofjz9\" style=\"display:none\">pproach based on\n",
       "distributional semantics and deep learning with neural networks to model and\n",
       "link text to a scarce set of bank distress events. Through unsupervised\n",
       "training, we learn semantic vector representations of news articles as\n",
       "predictors of distress events. The predictive model that we learn can signal\n",
       "coinciding stress with an aggregated index at bank or European level, while\n",
       "crucially allowing for automatic extraction of text descriptions of the events,\n",
       "based on passages with high stress levels. The method offers insight that\n",
       "models based on other types of data cannot provide, while offering a general\n",
       "means for interpreting this type of semantic-predictive model. We model bank\n",
       "distress with data on 243 events and 6.6M news articles for 101 large European\n",
       "banks.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/earnings-prediction-with-deep-leaning\">Earnings Prediction with Deep Learning</a> <small style=\"background: #eee\">0.765</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> Convolution\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        In the financial sector, a reliable forecast the future financial performance of a company is of great importance for investors' investment decisions. In this paper we compare long-term short-term mem <a href=\"#\" onclick=\"$('#abstract_dnEQApacQf').toggle();\">...</a>\n",
       "        <span id=\"abstract_dnEQApacQf\" style=\"display:none\">ory (LSTM) networks to temporal convolution network (TCNs) in the prediction of future earnings per share (EPS). The experimental analysis is based on quarterly financial reporting data and daily stock market returns. For a broad sample of US firms, we find that both LSTMs outperform the naive persistent model with up to 30.0% more accurate predictions, while TCNs achieve and an improvement of 30.8%. Both types of networks are at least as accurate as analysts and exceed them by up to 12.2% (LSTM) and 13.2% (TCN).</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/deep-learning-bank-distress-from-news-and\">Deep learning bank distress from news and numerical financial data</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        In this paper we focus our attention on the exploitation of the information\n",
       "contained in financial news to enhance the performance of a classifier of bank\n",
       "distress. Such information should be analyzed <a href=\"#\" onclick=\"$('#abstract_-TQl6tgFCc').toggle();\">...</a>\n",
       "        <span id=\"abstract_-TQl6tgFCc\" style=\"display:none\"> and inserted into the predictive\n",
       "model in the most efficient way and this task deals with all the issues related\n",
       "to text analysis and specifically analysis of news media. Among the different\n",
       "models proposed for such purpose, we investigate one of the possible deep\n",
       "learning approaches, based on a doc2vec representation of the textual data, a\n",
       "kind of neural network able to map the sequential and symbolic text input onto\n",
       "a reduced latent semantic space. Afterwards, a second supervised neural network\n",
       "is trained combining news data with standard financial figures to classify\n",
       "banks whether in distressed or tranquil states, based on a small set of known\n",
       "distress events. Then the final aim is not only the improvement of the\n",
       "predictive performance of the classifier but also to assess the importance of\n",
       "news data in the classification process. Does news data really bring more\n",
       "useful information not contained in standard financial variables? Our results\n",
       "seem to confirm such hypothesis.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/mining-public-opinion-on-twitter-about\">Mining Public Opinion on Twitter about Natural Disaster Response Using Machine Learning Techniques</a> <small style=\"background: #eee\">0.977</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Disaster Response, Sentiment Analysis, Time Series\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        With the development of the Internet, social media has become an essential channel for posting disaster-related information. Analyzing attitudes hidden in these texts, known as sentiment analysis, is  <a href=\"#\" onclick=\"$('#abstract_voe8fPqNyR').toggle();\">...</a>\n",
       "        <span id=\"abstract_voe8fPqNyR\" style=\"display:none\">crucial for the government or relief agencies to improve disaster response efficiency, but it has not received sufficient attention. This paper aims to fill this gap by focusing on investigating public attitudes towards disaster response and analyzing targeted relief supplies during disaster relief. The research comprises four steps. First, this paper implements Python in grasping Twitter data, and then, we assess public perceptron quantitatively by these opinioned texts, which contain information like the demand for targeted relief supplies, satisfactions of disaster response and fear of the public. A natural disaster dataset with sentiment labels is created, which contains 49,816 Twitter data about natural disasters in the United States. Second, this paper proposes eight machine learning models for sentiment prediction, which are the most popular models used in classification problems. Third, the comparison of these models is conducted via various metrics, and this paper also discusses the optimization method of these models from the perspective of model parameters and input data structures. Finally, a set of real-world instances are studied from the perspective of analyzing changes of public opinion during different natural disasters and understanding the relationship between the same hazard and time series. Results in this paper demonstrate the feasibility and validation of the proposed research approach and provide relief agencies with insights into better disaster response.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/firms-default-prediction-with-machine\">Firms Default Prediction with Machine Learning</a> <small style=\"background: #eee\">0.966</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Academics and practitioners have studied over the years models for predicting firms bankruptcy, using statistical and machine-learning approaches. An earlier sign that a company has financial difficul <a href=\"#\" onclick=\"$('#abstract_TxuUWnrZy-').toggle();\">...</a>\n",
       "        <span id=\"abstract_TxuUWnrZy-\" style=\"display:none\">ties and may eventually bankrupt is going in \\emph{default}, which, loosely speaking means that the company has been having difficulties in repaying its loans towards the banking system. Firms default status is not technically a failure but is very relevant for bank lending policies and often anticipates the failure of the company. Our study uses, for the first time according to our knowledge, a very large database of granular credit data from the Italian Central Credit Register of Bank of Italy that contain information on all Italian companies' past behavior towards the entire Italian banking system to predict their default using machine-learning techniques. Furthermore, we combine these data with other information regarding companies' public balance sheet data. We find that ensemble techniques and random forest provide the best results, corroborating the findings of Barboza et al. (Expert Syst. Appl., 2017).</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/what-you-say-and-how-you-say-it-matters\">What You Say and How You Say It Matters: Predicting Stock Volatility Using Verbal and Vocal Cues</a> <small style=\"background: #eee\">0.758</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Predicting financial risk is an essential task in financial market. Prior research has shown that textual information in a firm{'}s financial statement can be used to predict its stock{'}s risk level. <a href=\"#\" onclick=\"$('#abstract_xhxiXU3p87').toggle();\">...</a>\n",
       "        <span id=\"abstract_xhxiXU3p87\" style=\"display:none\"> Nowadays, firm CEOs communicate information not only verbally through press releases and financial reports, but also nonverbally through investor meetings and earnings conference calls. There are anecdotal evidences that CEO{'}s vocal features, such as emotions and voice tones, can reveal the firm{'}s performance. However, how vocal features can be used to predict risk levels, and to what extent, is still unknown. To fill the gap, we obtain earnings call audio recordings and textual transcripts for S{\\&}P 500 companies in recent years. We propose a multimodal deep regression model (MDRM) that jointly model CEO{'}s verbal (from text) and vocal (from audio) information in a conference call. Empirical results show that our model that jointly considers verbal and vocal features achieves significant and substantial prediction error reduction. We also discuss several interesting findings and the implications to financial markets. The processed earnings conference calls data (text and audio) are released for readers who are interested in reproducing the results or designing trading strategy.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/proficiency-comparison-of-ladtree-and-reptree\">Proficiency Comparison of LADTree and REPTree Classifiers for Credit Risk Forecast</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Predicting the Credit Defaulter is a perilous task of Financial Industries\n",
       "like Banks. Ascertaining non-payer before giving loan is a significant and\n",
       "conflict-ridden task of the Banker. Classification <a href=\"#\" onclick=\"$('#abstract_vWSJehG2Jb').toggle();\">...</a>\n",
       "        <span id=\"abstract_vWSJehG2Jb\" style=\"display:none\"> techniques are the better\n",
       "choice for predictive analysis like finding the claimant, whether he/she is an\n",
       "unpretentious customer or a cheat. Defining the outstanding classifier is a\n",
       "risky assignment for any industrialist like a banker. This allow computer\n",
       "science researchers to drill down efficient research works through evaluating\n",
       "different classifiers and finding out the best classifier for such predictive\n",
       "problems. This research work investigates the productivity of LADTree\n",
       "Classifier and REPTree Classifier for the credit risk prediction and compares\n",
       "their fitness through various measures. German credit dataset has been taken\n",
       "and used to predict the credit risk with a help of open source machine learning\n",
       "tool.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/a-personal-model-of-trumpery-deception\">A personal model of trumpery: Deception detection in a real-world high-stakes setting</a> <small style=\"background: #eee\">0.976</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Deception Detection\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Language use reveals information about who we are and how we feel1-3. One of\n",
       "the pioneers in text analysis, Walter Weintraub, manually counted which types\n",
       "of words people used in medical interviews an <a href=\"#\" onclick=\"$('#abstract_42La-Y1cma').toggle();\">...</a>\n",
       "        <span id=\"abstract_42La-Y1cma\" style=\"display:none\">d showed that the frequency of\n",
       "first-person singular pronouns (i.e., I, me, my) was a reliable indicator of\n",
       "depression, with depressed people using I more often than people who are not\n",
       "depressed4. Several studies have demonstrated that language use also differs\n",
       "between truthful and deceptive statements5-7, but not all differences are\n",
       "consistent across people and contexts, making prediction difficult8. Here we\n",
       "show how well linguistic deception detection performs at the individual level\n",
       "by developing a model tailored to a single individual: the current US\n",
       "president. Using tweets fact-checked by an independent third party (Washington\n",
       "Post), we found substantial linguistic differences between factually correct\n",
       "and incorrect tweets and developed a quantitative model based on these\n",
       "differences. Next, we predicted whether out-of-sample tweets were either\n",
       "factually correct or incorrect and achieved a 73% overall accuracy. Our results\n",
       "demonstrate the power of linguistic analysis in real-world deception research\n",
       "when applied at the individual level and provide evidence that factually\n",
       "incorrect tweets are not random mistakes of the sender.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/bank-distress-in-the-news-describing-events\">Bank distress in the news: Describing events through deep learning</a> <small style=\"background: #eee\">0.965</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        While many models are purposed for detecting the occurrence of significant\n",
       "events in financial systems, the task of providing qualitative detail on the\n",
       "developments is not usually as well automated. W <a href=\"#\" onclick=\"$('#abstract_tMNINWILd7').toggle();\">...</a>\n",
       "        <span id=\"abstract_tMNINWILd7\" style=\"display:none\">e present a deep learning\n",
       "approach for detecting relevant discussion in text and extracting natural\n",
       "language descriptions of events. Supervised by only a small set of event\n",
       "information, comprising entity names and dates, the model is leveraged by\n",
       "unsupervised learning of semantic vector representations on extensive text\n",
       "data. We demonstrate applicability to the study of financial risk based on news\n",
       "(6.6M articles), particularly bank distress and government interventions (243\n",
       "events), where indices can signal the level of bank-stress-related reporting at\n",
       "the entity level, or aggregated at national or European level, while being\n",
       "coupled with explanations. Thus, we exemplify how text, as timely, widely\n",
       "available and descriptive data, can serve as a useful complementary source of\n",
       "information for financial and systemic risk analytics.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/the-value-of-text-for-small-business-default\">The value of text for small business default prediction: A deep learning approach</a> <small style=\"background: #eee\">0.756</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> Residual Connection, Attention Dropout, Linear Warmup With Linear Decay, Weight Decay, GELU, Dense Connections, Adam, WordPiece, Softmax, Dropout, Multi-Head Attention, Layer Normalization, Scaled Dot-Product Attention, BERT\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Compared to consumer lending, Micro, Small and Medium Enterprise (mSME) credit risk modelling is particularly challenging, as, often, the same sources of information are not available. It is, therefor <a href=\"#\" onclick=\"$('#abstract_-7VaGKvAv0').toggle();\">...</a>\n",
       "        <span id=\"abstract_-7VaGKvAv0\" style=\"display:none\">e, standard policy for a loan officer to provide a textual loan assessment to mitigate limited data availability. In turn, this statement is analysed by a credit expert alongside any available standard credit data. In our paper, we exploit recent advances from the field of Deep Learning and Natural Language Processing (NLP), including the BERT (Bidirectional Encoder Representations from Transformers) model, to extract information from 60000 textual assessments provided by a lender. We consider the performance in terms of the AUC (Area Under the receiver operating characteristic Curve) metric and find that the text alone is surprisingly effective for predicting default. However, when combined with traditional data, it yields no additional predictive capability, with performance dependent on the length of the text. Our proposed deep learning model does, however, appear to be robust to the quality of the text and therefore suitable for partly automating the mSME lending process. We additionally go on to demonstrate how the content of loan assessments influences performance, leading us to a series of recommendations on a new strategy for the collection of future mSME loan assessments.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/the-value-of-text-for-small-business-default\">The value of text for small business default prediction: A deep learning approach</a> <small style=\"background: #eee\">0.977</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> Residual Connection, Attention Dropout, Linear Warmup With Linear Decay, Weight Decay, GELU, Dense Connections, Adam, WordPiece, Softmax, Dropout, Multi-Head Attention, Layer Normalization, Scaled Dot-Product Attention, BERT\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Compared to consumer lending, Micro, Small and Medium Enterprise (mSME) credit risk modelling is particularly challenging, as, often, the same sources of information are not available. It is, therefor <a href=\"#\" onclick=\"$('#abstract_-7VaGKvAv0').toggle();\">...</a>\n",
       "        <span id=\"abstract_-7VaGKvAv0\" style=\"display:none\">e, standard policy for a loan officer to provide a textual loan assessment to mitigate limited data availability. In turn, this statement is analysed by a credit expert alongside any available standard credit data. In our paper, we exploit recent advances from the field of Deep Learning and Natural Language Processing (NLP), including the BERT (Bidirectional Encoder Representations from Transformers) model, to extract information from 60000 textual assessments provided by a lender. We consider the performance in terms of the AUC (Area Under the receiver operating characteristic Curve) metric and find that the text alone is surprisingly effective for predicting default. However, when combined with traditional data, it yields no additional predictive capability, with performance dependent on the length of the text. Our proposed deep learning model does, however, appear to be robust to the quality of the text and therefore suitable for partly automating the mSME lending process. We additionally go on to demonstrate how the content of loan assessments influences performance, leading us to a series of recommendations on a new strategy for the collection of future mSME loan assessments.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/top-comment-or-flop-comment-predicting-and\">Top Comment or Flop Comment? Predicting and Explaining User Engagement in Online News Discussions</a> <small style=\"background: #eee\">0.976</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Comment sections below online news articles enjoy growing popularity among readers. However, the overwhelming number of comments makes it infeasible for the average news consumer to read all of them a <a href=\"#\" onclick=\"$('#abstract_V8xmUysY3Y').toggle();\">...</a>\n",
       "        <span id=\"abstract_V8xmUysY3Y\" style=\"display:none\">nd hinders engaging discussions. Most platforms display comments in chronological order, which neglects that some of them are more relevant to users and are better conversation starters. In this paper, we systematically analyze user engagement in the form of the upvotes and replies that a comment receives. Based on comment texts, we train a model to distinguish comments that have either a high or low chance of receiving many upvotes and replies. Our evaluation on user comments from TheGuardian.com compares recurrent and convolutional neural network models, and a traditional feature-based classifier. Further, we investigate what makes some comments more engaging than others. To this end, we identify engagement triggers and arrange them in a taxonomy. Explanation methods for neural networks reveal which input words have the strongest influence on our model's predictions. In addition, we evaluate on a dataset of product reviews, which exhibit similar properties as user comments, such as featuring upvotes for helpfulness.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/modeling-institutional-credit-risk-with\">Modeling Institutional Credit Risk with Financial News</a> <small style=\"background: #eee\">0.964</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Credit risk management, the practice of mitigating losses by understanding the adequacy of a borrower's capital and loan loss reserves, has long been imperative to any financial institution's long-ter <a href=\"#\" onclick=\"$('#abstract_ykRqUKc8Zk').toggle();\">...</a>\n",
       "        <span id=\"abstract_ykRqUKc8Zk\" style=\"display:none\">m sustainability and growth. MassMutual is no exception. The company is keen on effectively monitoring downgrade risk, or the risk associated with the event when credit rating of a company deteriorates. Current work in downgrade risk modeling depends on multiple variations of quantitative measures provided by third-party rating agencies and risk management consultancy companies. As these structured numerical data become increasingly commoditized among institutional investors, there has been a wide push into using alternative sources of data, such as financial news, earnings call transcripts, or social media content, to possibly gain a competitive edge in the industry. The volume of qualitative information or unstructured text data has exploded in the past decades and is now available for due diligence to supplement quantitative measures of credit risk. This paper proposes a predictive downgrade model using solely news data represented by neural network embeddings. The model standalone achieves an Area Under the Receiver Operating Characteristic Curve (AUC) of more than 80 percent. The output probability from this news model, as an additional feature, improves the performance of our benchmark model using only quantitative measures by more than 5 percent in terms of both AUC and recall rate. A qualitative evaluation also indicates that news articles related to our predicted downgrade events are specially relevant and high-quality in our business context.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "        <h3>Seed. <a href=\"https://paperswithcode.com/paper/hrl4in-hierarchical-reinforcement-learning\">HRL4IN: Hierarchical Reinforcement Learning for Interactive Navigation with Mobile Manipulators</a> <small style=\"background: #eee\">0.000</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Hierarchical Reinforcement Learning\n",
       "        <b>Methods:</b> Entropy Regularization, PPO\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Most common navigation tasks in human environments require auxiliary arm interactions, e.g. opening doors, pressing buttons and pushing obstacles away. This type of navigation tasks, which we call Int <a href=\"#\" onclick=\"$('#abstract_0PIfIxFX5M').toggle();\">...</a>\n",
       "        <span id=\"abstract_0PIfIxFX5M\" style=\"display:none\">eractive Navigation, requires the use of mobile manipulators: mobile bases with manipulation capabilities. Interactive Navigation tasks are usually long-horizon and composed of heterogeneous phases of pure navigation, pure manipulation, and their combination. Using the wrong part of the embodiment is inefficient and hinders progress. We propose HRL4IN, a novel Hierarchical RL architecture for Interactive Navigation tasks. HRL4IN exploits the exploration benefits of HRL over flat RL for long-horizon tasks thanks to temporally extended commitments towards subgoals. Different from other HRL solutions, HRL4IN handles the heterogeneous nature of the Interactive Navigation task by creating subgoals in different spaces in different phases of the task. Moreover, HRL4IN selects different parts of the embodiment to use for each phase, improving energy efficiency. We evaluate HRL4IN against flat PPO and HAC, a state-of-the-art HRL algorithm, on Interactive Navigation in two environments - a 2D grid-world environment and a 3D environment with physics simulation. We show that HRL4IN significantly outperforms its baselines in terms of task performance and energy efficiency. More information is available at https://sites.google.com/view/hrl4in.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "         <hr />\n",
       "    <table><thead><tr>\n",
       "    <th width=\"25%\">General purpose</th>\n",
       "    <th width=\"25%\">Task-related</th>\n",
       "    <th width=\"25%\">Method-related</th>\n",
       "    <th width=\"25%\">Dataset-related</th>\n",
       "    </thead><tbody>\n",
       "    <tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/guided-dyna-q-for-mobile-robot-exploration\">Guided Dyna-Q for Mobile Robot Exploration and Navigation</a> <small style=\"background: #eee\">0.811</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Model-based reinforcement learning (RL) enables an agent to learn world models from trial-and-error experiences toward achieving long-term goals. Automated planning, on the other hand, can be used for <a href=\"#\" onclick=\"$('#abstract_U0hgrQy-uk').toggle();\">...</a>\n",
       "        <span id=\"abstract_U0hgrQy-uk\" style=\"display:none\"> accomplishing tasks through reasoning with declarative action knowledge. Despite their shared goal of completing complex tasks, the development of RL and automated planning has mainly been isolated due to their different modalities of computation. Focusing on improving model-based RL agent's exploration strategy and sample efficiency, we develop Guided Dyna-Q (GDQ) to enable RL agents to reason with action knowledge to avoid exploring less-relevant states toward more efficient task accomplishment. GDQ has been evaluated in simulation and using a mobile robot conducting navigation tasks in an office environment. Results show that GDQ reduces the effort in exploration while improving the quality of learned policies.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/interactive-gibson-a-benchmark-for\">Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments</a> <small style=\"background: #eee\">0.997</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Robot Navigation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We present Interactive Gibson Benchmark, the first comprehensive benchmark for training and evaluating Interactive Navigation: robot navigation strategies where physical interaction with objects is al <a href=\"#\" onclick=\"$('#abstract_yf-yNtXeH3').toggle();\">...</a>\n",
       "        <span id=\"abstract_yf-yNtXeH3\" style=\"display:none\">lowed and even encouraged to accomplish a task. For example, the robot can move objects if needed in order to clear a path leading to the goal location. Our benchmark comprises two novel elements: 1) a new experimental setup, the Interactive Gibson Environment, which simulates high fidelity visuals of indoor scenes, and high fidelity physical dynamics of the robot and common objects found in these scenes; 2) a set of Interactive Navigation metrics which allows one to study the interplay between navigation and physical interaction. We present and evaluate multiple learning-based baselines in Interactive Gibson, and provide insights into regimes of navigation with different trade-offs between navigation path efficiency and disturbance of surrounding objects. We make our benchmark publicly available(https://sites.google.com/view/interactivegibsonenv) and encourage researchers from all disciplines in robotics (e.g. planning, learning, control) to propose, evaluate, and compare their Interactive Navigation solutions in Interactive Gibson.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/tpo-tree-search-policy-optimization-for\">TPO: TREE SEARCH POLICY OPTIMIZATION FOR CONTINUOUS ACTION SPACES</a> <small style=\"background: #eee\">0.989</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> Entropy Regularization, PPO\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Monte Carlo Tree Search (MCTS) has achieved impressive results on a range of discrete environments, such as Go, Mario and Arcade games, but it has not yet fulfilled its true potential in continuous do <a href=\"#\" onclick=\"$('#abstract_739toS1nLl').toggle();\">...</a>\n",
       "        <span id=\"abstract_739toS1nLl\" style=\"display:none\">mains.In this work, we introduceTPO, a tree search based policy optimization method for continuous environments. TPO takes a hybrid approach to policy optimization.  Building the MCTS tree in a continuous action space and updating the policy gradient using off-policy MCTS trajectories are non-trivial. To overcome these challenges, we propose limiting tree search branching factor by drawing only few action samples from the policy distribution and define a new loss function based on the trajectories’ mean and standard deviations.  Our approach led to some non-intuitive findings.  MCTS training generally requires a large number of samples and simulations. However, we observed that bootstrappingtree search with a pre-trained policy allows us to achieve high quality results with a low MCTS branching factor and few number of simulations. Without the proposed policy bootstrapping, continuous MCTS would require a much larger branching factor and simulation count, rendering it computationally and prohibitively expensive. In our experiments, we use PPO as our baseline policy optimization algorithm. TPO significantly improves the policy on nearly all of our benchmarks.  For example, in complex environments such as Humanoid, we achieve a 2.5×improvement over the baseline algorithm.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/interactive-gibson-a-benchmark-for\">Interactive Gibson Benchmark: A Benchmark for Interactive Navigation in Cluttered Environments</a> <small style=\"background: #eee\">0.980</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Robot Navigation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We present Interactive Gibson Benchmark, the first comprehensive benchmark for training and evaluating Interactive Navigation: robot navigation strategies where physical interaction with objects is al <a href=\"#\" onclick=\"$('#abstract_yf-yNtXeH3').toggle();\">...</a>\n",
       "        <span id=\"abstract_yf-yNtXeH3\" style=\"display:none\">lowed and even encouraged to accomplish a task. For example, the robot can move objects if needed in order to clear a path leading to the goal location. Our benchmark comprises two novel elements: 1) a new experimental setup, the Interactive Gibson Environment, which simulates high fidelity visuals of indoor scenes, and high fidelity physical dynamics of the robot and common objects found in these scenes; 2) a set of Interactive Navigation metrics which allows one to study the interplay between navigation and physical interaction. We present and evaluate multiple learning-based baselines in Interactive Gibson, and provide insights into regimes of navigation with different trade-offs between navigation path efficiency and disturbance of surrounding objects. We make our benchmark publicly available(https://sites.google.com/view/interactivegibsonenv) and encourage researchers from all disciplines in robotics (e.g. planning, learning, control) to propose, evaluate, and compare their Interactive Navigation solutions in Interactive Gibson.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/appld-adaptive-planner-parameter-learning\">APPLD: Adaptive Planner Parameter Learning from Demonstration</a> <small style=\"background: #eee\">0.811</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Robot Navigation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Existing autonomous robot navigation systems allow robots to move from one point to another in a collision-free manner. However, when facing new environments, these systems generally require re-tuning <a href=\"#\" onclick=\"$('#abstract_8nX-pgA191').toggle();\">...</a>\n",
       "        <span id=\"abstract_8nX-pgA191\" style=\"display:none\"> by expert roboticists with a good understanding of the inner workings of the navigation system. In contrast, even users who are unversed in the details of robot navigation algorithms can generate desirable navigation behavior in new environments via teleoperation. In this paper, we introduce APPLD, Adaptive Planner Parameter Learning from Demonstration, that allows existing navigation systems to be successfully applied to new complex environments, given only a human teleoperated demonstration of desirable navigation. APPLD is verified on two robots running different navigation systems in different environments. Experimental results show that APPLD can outperform navigation systems with the default and expert-tuned parameters, and even the human demonstrator themselves.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/l2b-learning-to-balance-the-safety-efficiency\">L2B: Learning to Balance the Safety-Efficiency Trade-off in Interactive Crowd-aware Robot Navigation</a> <small style=\"background: #eee\">0.995</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Robot Navigation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This work presents a deep reinforcement learning framework for interactive navigation in a crowded place. Our proposed approach, Learning to Balance (L2B) framework enables mobile robot agents to stee <a href=\"#\" onclick=\"$('#abstract_vd2sM6IhEk').toggle();\">...</a>\n",
       "        <span id=\"abstract_vd2sM6IhEk\" style=\"display:none\">r safely towards their destinations by avoiding collisions with a crowd, while actively clearing a path by asking nearby pedestrians to make room, if necessary, to keep their travel efficient. We observe that the safety and efficiency requirements in crowd-aware navigation have a trade-off in the presence of social dilemmas between the agent and the crowd. On the one hand, intervening in pedestrian paths too much to achieve instant efficiency will result in collapsing a natural crowd flow and may eventually put everyone, including the self, at risk of collisions. On the other hand, keeping in silence to avoid every single collision will lead to the agent's inefficient travel. With this observation, our L2B framework augments the reward function used in learning an interactive navigation policy to penalize frequent active path clearing and passive collision avoidance, which substantially improves the balance of the safety-efficiency trade-off. We evaluate our L2B framework in a challenging crowd simulation and demonstrate its superiority, in terms of both navigation success and collision rate, over a state-of-the-art navigation approach.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/policy-optimization-with-model-based\">Policy Optimization with Model-based Explorations</a> <small style=\"background: #eee\">0.988</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Atari Games, Decision Making\n",
       "        <b>Methods:</b> Entropy Regularization, PPO\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Model-free reinforcement learning methods such as the Proximal Policy\n",
       "Optimization algorithm (PPO) have successfully applied in complex\n",
       "decision-making problems such as Atari games. However, these met <a href=\"#\" onclick=\"$('#abstract_HsibqlQitZ').toggle();\">...</a>\n",
       "        <span id=\"abstract_HsibqlQitZ\" style=\"display:none\">hods suffer\n",
       "from high variances and high sample complexity. On the other hand, model-based\n",
       "reinforcement learning methods that learn the transition dynamics are more\n",
       "sample efficient, but they often suffer from the bias of the transition\n",
       "estimation. How to make use of both model-based and model-free learning is a\n",
       "central problem in reinforcement learning. In this paper, we present a new\n",
       "technique to address the trade-off between exploration and exploitation, which\n",
       "regards the difference between model-free and model-based estimations as a\n",
       "measure of exploration value. We apply this new technique to the PPO algorithm\n",
       "and arrive at a new policy optimization method, named Policy Optimization with\n",
       "Model-based Explorations (POME). POME uses two components to predict the\n",
       "actions' target values: a model-free one estimated by Monte-Carlo sampling and\n",
       "a model-based one which learns a transition model and predicts the value of the\n",
       "next state. POME adds the error of these two target estimations as the\n",
       "additional exploration value for each state-action pair, i.e, encourages the\n",
       "algorithm to explore the states with larger target errors which are hard to\n",
       "estimate. We compare POME with PPO on Atari 2600 games, and it shows that POME\n",
       "outperforms PPO on 33 games out of 49 games.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/counterfactual-reasoning-about-intent-for\">Counterfactual Reasoning about Intent for Interactive Navigation in Dynamic Environments</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making, Motion Planning, Robot Navigation, Visual Tracking\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Many modern robotics applications require robots to function autonomously in\n",
       "dynamic environments including other decision making agents, such as people or\n",
       "other robots. This calls for fast and scalab <a href=\"#\" onclick=\"$('#abstract_wCFVq-_jj8').toggle();\">...</a>\n",
       "        <span id=\"abstract_wCFVq-_jj8\" style=\"display:none\">le interactive motion planning.\n",
       "This requires models that take into consideration the other agent's intended\n",
       "actions in one's own planning. We present a real-time motion planning framework\n",
       "that brings together a few key components including intention inference by\n",
       "reasoning counterfactually about potential motion of the other agents as they\n",
       "work towards different goals. By using a light-weight motion model, we achieve\n",
       "efficient iterative planning for fluid motion when avoiding pedestrians, in\n",
       "parallel with goal inference for longer range movement prediction. This\n",
       "inference framework is coupled with a novel distributed visual tracking method\n",
       "that provides reliable and robust models for the current belief-state of the\n",
       "monitored environment. This combined approach represents a computationally\n",
       "efficient alternative to previously studied policy learning methods that often\n",
       "require significant offline training or calibration and do not yet scale to\n",
       "densely populated environments. We validate this framework with experiments\n",
       "involving multi-robot and human-robot navigation. We further validate the\n",
       "tracker component separately on much larger scale unconstrained pedestrian data\n",
       "sets.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/relmogen-leveraging-motion-generation-in\">ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation</a> <small style=\"background: #eee\">0.810</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Continuous Control, Hierarchical Reinforcement Learning\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Many Reinforcement Learning (RL) approaches use joint control signals (positions, velocities, torques) as action space for continuous control tasks. We propose to lift the action space to a higher lev <a href=\"#\" onclick=\"$('#abstract_1iy7ftHxyR').toggle();\">...</a>\n",
       "        <span id=\"abstract_1iy7ftHxyR\" style=\"display:none\">el in the form of subgoals for a motion generator (a combination of motion planner and trajectory executor). We argue that, by lifting the action space and by leveraging sampling-based motion planners, we can efficiently use RL to solve complex, long-horizon tasks that could not be solved with existing RL methods in the original action space. We propose ReLMoGen -- a framework that combines a learned policy to predict subgoals and a motion generator to plan and execute the motion needed to reach these subgoals. To validate our method, we apply ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation problems where interactions with the environment are required to reach the destination, and 2) Mobile Manipulation tasks, manipulation tasks that require moving the robot base. These problems are challenging because they are usually long-horizon, hard to explore during training, and comprise alternating phases of navigation and interaction. Our method is benchmarked on a diverse set of seven robotics tasks in photo-realistic simulation environments. In all settings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and Hierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding transferability between different motion generators at test time, indicating a great potential to transfer to real robots.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/relmogen-leveraging-motion-generation-in\">ReLMoGen: Leveraging Motion Generation in Reinforcement Learning for Mobile Manipulation</a> <small style=\"background: #eee\">0.995</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Continuous Control, Hierarchical Reinforcement Learning\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Many Reinforcement Learning (RL) approaches use joint control signals (positions, velocities, torques) as action space for continuous control tasks. We propose to lift the action space to a higher lev <a href=\"#\" onclick=\"$('#abstract_1iy7ftHxyR').toggle();\">...</a>\n",
       "        <span id=\"abstract_1iy7ftHxyR\" style=\"display:none\">el in the form of subgoals for a motion generator (a combination of motion planner and trajectory executor). We argue that, by lifting the action space and by leveraging sampling-based motion planners, we can efficiently use RL to solve complex, long-horizon tasks that could not be solved with existing RL methods in the original action space. We propose ReLMoGen -- a framework that combines a learned policy to predict subgoals and a motion generator to plan and execute the motion needed to reach these subgoals. To validate our method, we apply ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation problems where interactions with the environment are required to reach the destination, and 2) Mobile Manipulation tasks, manipulation tasks that require moving the robot base. These problems are challenging because they are usually long-horizon, hard to explore during training, and comprise alternating phases of navigation and interaction. Our method is benchmarked on a diverse set of seven robotics tasks in photo-realistic simulation environments. In all settings, ReLMoGen outperforms state-of-the-art Reinforcement Learning and Hierarchical Reinforcement Learning baselines. ReLMoGen also shows outstanding transferability between different motion generators at test time, indicating a great potential to transfer to real robots.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/towards-model-based-reinforcement-learning\">Towards Model-based Reinforcement Learning for Industry-near Environments</a> <small style=\"background: #eee\">0.988</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Q-Learning\n",
       "        <b>Methods:</b> AutoEncoder, Entropy Regularization, PPO\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep reinforcement learning has over the past few years shown great potential in learning near-optimal control in complex simulated environments with little visible information. Rainbow (Q-Learning) a <a href=\"#\" onclick=\"$('#abstract_h0QyXdxk9h').toggle();\">...</a>\n",
       "        <span id=\"abstract_h0QyXdxk9h\" style=\"display:none\">nd PPO (Policy Optimisation) have shown outstanding performance in a variety of tasks, including Atari 2600, MuJoCo, and Roboschool test suite. While these algorithms are fundamentally different, both suffer from high variance, low sample efficiency, and hyperparameter sensitivity that in practice, make these algorithms a no-go for critical operations in the industry. On the other hand, model-based reinforcement learning focuses on learning the transition dynamics between states in an environment. If these environment dynamics are adequately learned, a model-based approach is perhaps the most sample efficient method for learning agents to act in an environment optimally. The traits of model-based reinforcement are ideal for real-world environments where sampling is slow and for mission-critical operations. In the warehouse industry, there is an increasing motivation to minimise time and to maximise production. Currently, autonomous agents act suboptimally using handcrafted policies for significant portions of the state-space. In this paper, we present The Dreaming Variational Autoencoder v2 (DVAE-2), a model-based reinforcement learning algorithm that increases sample efficiency, hence enable algorithms with low sample efficiency function better in real-world environments. We introduce Deep Warehouse, a simulated environment for industry-near testing of autonomous agents in grid-based warehouses. Finally, we illustrate that DVAE-2 improves the sample efficiency for the Deep Warehouse compared to model-free methods.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/define-delayed-feedback-based-immersive\">DeFINE: Delayed Feedback based Immersive Navigation Environment for Studying Goal-Directed Human Navigation</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        With the advent of consumer-grade products for presenting an immersive virtual environment (VE), there is a growing interest in utilizing VEs for testing human navigation behavior. However, preparing  <a href=\"#\" onclick=\"$('#abstract_YcoqUk9LDQ').toggle();\">...</a>\n",
       "        <span id=\"abstract_YcoqUk9LDQ\" style=\"display:none\">a VE still requires a high level of technical expertise in computer graphics and virtual reality, posing a significant hurdle to embracing the emerging technology. To address this issue, this paper presents Delayed Feedback based Immersive Navigation Environment (DeFINE), a framework that allows for easy creation and administration of navigation tasks within customizable VEs via intuitive graphical user interfaces and simple settings files. Importantly, DeFINE has a built-in capability to provide performance feedback to participants during an experiment, a feature that is critically missing in other similar frameworks. To demonstrate the usability of DeFINE from both experimentalists' and participants' perspectives, a case study was conducted in which participants navigated to a hidden goal location with feedback that differentially weighted speed and accuracy of their responses. In addition, the participants evaluated DeFINE in terms of its ease of use, required workload, and proneness to induce cybersickness. Results showed that the participants' navigation performance was affected differently by the types of feedback they received, and they rated DeFINE highly in the evaluations, validating DeFINE's architecture for investigating human navigation in VEs. With its rich out-of-the-box functionality and great customizability due to open-source licensing, DeFINE makes VEs significantly more accessible to many researchers.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/motion-planner-augmented-reinforcement\">Motion Planner Augmented Reinforcement Learning for Robot Manipulation in Obstructed Environments</a> <small style=\"background: #eee\">0.794</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep reinforcement learning (RL) agents are able to learn contact-rich manipulation tasks by maximizing a reward signal, but require large amounts of experience, especially in environments with many o <a href=\"#\" onclick=\"$('#abstract_p7lWXCGHeh').toggle();\">...</a>\n",
       "        <span id=\"abstract_p7lWXCGHeh\" style=\"display:none\">bstacles that complicate exploration. In contrast, motion planners use explicit models of the agent and environment to plan collision-free paths to faraway goals, but suffer from inaccurate models in tasks that require contacts with the environment. To combine the benefits of both approaches, we propose motion planner augmented RL (MoPA-RL) which augments the action space of an RL agent with the long-horizon planning capabilities of motion planners. Based on the magnitude of the action, our approach smoothly transitions between directly executing the action and invoking a motion planner. We evaluate our approach on various simulated manipulation tasks and compare it to alternative action spaces in terms of learning efficiency and safety. The experiments demonstrate that MoPA-RL increases learning efficiency, leads to a faster exploration, and results in safer policies that avoid collisions with the environment. Videos and code are available at https://clvrai.com/mopa-rl .</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/the-streetlearn-environment-and-dataset\">The StreetLearn Environment and Dataset</a> <small style=\"background: #eee\">0.986</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Navigation is a rich and well-grounded problem domain that drives progress in\n",
       "many different areas of research: perception, planning, memory, exploration,\n",
       "and optimisation in particular. Historically  <a href=\"#\" onclick=\"$('#abstract_gy1QWw4vFZ').toggle();\">...</a>\n",
       "        <span id=\"abstract_gy1QWw4vFZ\" style=\"display:none\">these challenges have been\n",
       "separately considered and solutions built that rely on stationary datasets -\n",
       "for example, recorded trajectories through an environment. These datasets\n",
       "cannot be used for decision-making and reinforcement learning, however, and in\n",
       "general the perspective of navigation as an interactive learning task, where\n",
       "the actions and behaviours of a learning agent are learned simultaneously with\n",
       "the perception and planning, is relatively unsupported. Thus, existing\n",
       "navigation benchmarks generally rely on static datasets (Geiger et al., 2013;\n",
       "Kendall et al., 2015) or simulators (Beattie et al., 2016; Shah et al., 2018).\n",
       "To support and validate research in end-to-end navigation, we present\n",
       "StreetLearn: an interactive, first-person, partially-observed visual\n",
       "environment that uses Google Street View for its photographic content and broad\n",
       "coverage, and give performance baselines for a challenging goal-driven\n",
       "navigation task. The environment code, baseline agent code, and the dataset are\n",
       "available at http://streetlearn.cc</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/queueing-network-controls-via-deep\">Queueing Network Controls via Deep Reinforcement Learning</a> <small style=\"background: #eee\">0.987</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> Entropy Regularization, PPO\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Novel advanced policy gradient (APG) methods, such as Trust Region policy optimization and Proximal policy optimization (PPO), have become the dominant reinforcement learning algorithms because of the <a href=\"#\" onclick=\"$('#abstract_1mgC7w4Sis').toggle();\">...</a>\n",
       "        <span id=\"abstract_1mgC7w4Sis\" style=\"display:none\">ir ease of implementation and good practical performance. A conventional setup for notoriously difficult queueing network control problems is a Markov decision problem (MDP) that has three features: infinite state space, unbounded costs, and long-run average cost objective. We extend the theoretical framework of these APG methods for such MDP problems. The resulting PPO algorithm is tested on a parallel-server system and large-size multiclass queueing networks. The algorithm consistently generates control policies that outperform state-of-art heuristics in literature in a variety of load conditions from light to heavy traffic. These policies are demonstrated to be near-optimal when the optimal policy can be computed. A key to the successes of our PPO algorithm is the use of three variance reduction techniques in estimating the relative value function via sampling. First, we use a discounted relative value function as an approximation of the relative value function. Second, we propose regenerative simulation to estimate the discounted relative value function. Finally, we incorporate the approximating martingale-process method into the regenerative estimator.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/minos-multimodal-indoor-simulator-for\">MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments</a> <small style=\"background: #eee\">0.978</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We present MINOS, a simulator designed to support the development of\n",
       "multisensory models for goal-directed navigation in complex indoor\n",
       "environments. The simulator leverages large datasets of complex  <a href=\"#\" onclick=\"$('#abstract_ReLKnwwfo2').toggle();\">...</a>\n",
       "        <span id=\"abstract_ReLKnwwfo2\" style=\"display:none\">3D environments\n",
       "and supports flexible configuration of multimodal sensor suites. We use MINOS\n",
       "to benchmark deep-learning-based navigation methods, to analyze the influence\n",
       "of environmental complexity on navigation performance, and to carry out a\n",
       "controlled study of multimodality in sensorimotor learning. The experiments\n",
       "show that current deep reinforcement learning approaches fail in large\n",
       "realistic environments. The experiments also indicate that multimodality is\n",
       "beneficial in learning to navigate cluttered scenes. MINOS is released\n",
       "open-source to the research community at http://minosworld.org . A video that\n",
       "shows MINOS can be found at https://youtu.be/c0mL9K64q84</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/human-interactive-subgoal-supervision-for\">Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning</a> <small style=\"background: #eee\">0.789</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Humans are able to understand and perform complex tasks by strategically\n",
       "structuring the tasks into incremental steps or subgoals. For a robot\n",
       "attempting to learn to perform a sequential task with cri <a href=\"#\" onclick=\"$('#abstract_5I8jqRFQPy').toggle();\">...</a>\n",
       "        <span id=\"abstract_5I8jqRFQPy\" style=\"display:none\">tical subgoal states,\n",
       "such states can provide a natural opportunity for interaction with a human\n",
       "expert. This paper analyzes the benefit of incorporating a notion of subgoals\n",
       "into Inverse Reinforcement Learning (IRL) with a Human-In-The-Loop (HITL)\n",
       "framework. The learning process is interactive, with a human expert first\n",
       "providing input in the form of full demonstrations along with some subgoal\n",
       "states. These subgoal states define a set of subtasks for the learning agent to\n",
       "complete in order to achieve the final goal. The learning agent queries for\n",
       "partial demonstrations corresponding to each subtask as needed when the agent\n",
       "struggles with the subtask. The proposed Human Interactive IRL (HI-IRL)\n",
       "framework is evaluated on several discrete path-planning tasks. We demonstrate\n",
       "that subgoal-based interactive structuring of the learning task results in\n",
       "significantly more efficient learning, requiring only a fraction of the\n",
       "demonstration data needed for learning the underlying reward function with the\n",
       "baseline IRL model.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/sim-to-real-transfer-with-incremental\">Sim-to-Real Transfer with Incremental Environment Complexity for Reinforcement Learning of Depth-Based Robot Navigation</a> <small style=\"background: #eee\">0.985</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Robot Navigation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Transferring learning-based models to the real world remains one of the hardest problems in model-free control theory. Due to the cost of data collection on a real robot and the limited sample efficie <a href=\"#\" onclick=\"$('#abstract_4Sv6cMtL1p').toggle();\">...</a>\n",
       "        <span id=\"abstract_4Sv6cMtL1p\" style=\"display:none\">ncy of Deep Reinforcement Learning algorithms, models are usually trained in a simulator which theoretically provides an infinite amount of data. Despite offering unbounded trial and error runs, the reality gap between simulation and the physical world brings little guarantee about the policy behavior in real operation. Depending on the problem, expensive real fine-tuning and/or a complex domain randomization strategy may be required to produce a relevant policy. In this paper, a Soft-Actor Critic (SAC) training strategy using incremental environment complexity is proposed to drastically reduce the need for additional training in the real world. The application addressed is depth-based mapless navigation, where a mobile robot should reach a given waypoint in a cluttered environment with no prior mapping information. Experimental results in simulated and real environments are presented to assess quantitatively the efficiency of the proposed approach, which demonstrated a success rate twice higher than a naive strategy.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/optimization-and-passive-flow-control-using\">Optimization and passive flow control using single-step deep reinforcement learning</a> <small style=\"background: #eee\">0.987</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> Entropy Regularization, PPO\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This research gauges the ability of deep reinforcement learning (DRL) techniques to assist the optimization and control of fluid mechanical systems. It combines a novel, \"degenerate\" version of the pr <a href=\"#\" onclick=\"$('#abstract_6UHOylnvxC').toggle();\">...</a>\n",
       "        <span id=\"abstract_6UHOylnvxC\" style=\"display:none\">oximal policy optimization (PPO) algorithm, that trains a neural network in optimizing the system only once per learning episode, and an in-house stabilized finite elements environment implementing the variational multiscale (VMS) method, that computes the numerical reward fed to the neural network. Three prototypical examples of separated flows in two dimensions are used as testbed for developing the methodology, each of which adds a layer of complexity due either to the unsteadiness of the flow solutions, or the sharpness of the objective function, or the dimension of the control parameter space. Relevance is carefully assessed by comparing systematically to reference data obtained by canonical direct and adjoint methods. Beyond adding value to the shallow literature on this subject, these findings establish the potential of single-step PPO for reliable black-box optimization of computational fluid dynamics (CFD) systems, which paves the way for future progress in optimal flow control using this new class of methods.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/l2b-learning-to-balance-the-safety-efficiency\">L2B: Learning to Balance the Safety-Efficiency Trade-off in Interactive Crowd-aware Robot Navigation</a> <small style=\"background: #eee\">0.977</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Robot Navigation\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        This work presents a deep reinforcement learning framework for interactive navigation in a crowded place. Our proposed approach, Learning to Balance (L2B) framework enables mobile robot agents to stee <a href=\"#\" onclick=\"$('#abstract_vd2sM6IhEk').toggle();\">...</a>\n",
       "        <span id=\"abstract_vd2sM6IhEk\" style=\"display:none\">r safely towards their destinations by avoiding collisions with a crowd, while actively clearing a path by asking nearby pedestrians to make room, if necessary, to keep their travel efficient. We observe that the safety and efficiency requirements in crowd-aware navigation have a trade-off in the presence of social dilemmas between the agent and the crowd. On the one hand, intervening in pedestrian paths too much to achieve instant efficiency will result in collapsing a natural crowd flow and may eventually put everyone, including the self, at risk of collisions. On the other hand, keeping in silence to avoid every single collision will lead to the agent's inefficient travel. With this observation, our L2B framework augments the reward function used in learning an interactive navigation policy to penalize frequent active path clearing and passive collision avoidance, which substantially improves the balance of the safety-efficiency trade-off. We evaluate our L2B framework in a challenging crowd simulation and demonstrate its superiority, in terms of both navigation success and collision rate, over a state-of-the-art navigation approach.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "        <h3>Seed. <a href=\"https://paperswithcode.com/paper/stconvs2s-spatiotemporal-convolutional\">STConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for Weather Forecasting</a> <small style=\"background: #eee\">0.000</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Applying machine learning models to meteorological data brings many opportunities to the Geosciences field, such as predicting future weather conditions more accurately. In recent years, modeling mete <a href=\"#\" onclick=\"$('#abstract_WWyYWQkdwx').toggle();\">...</a>\n",
       "        <span id=\"abstract_WWyYWQkdwx\" style=\"display:none\">orological data with deep neural networks has become a relevant area of investigation. These works apply either recurrent neural networks (RNNs) or some hybrid approach mixing RNNs and convolutional neural networks (CNNs). In this work, we propose STConvS2S (short for Spatiotemporal Convolutional Sequence to Sequence Network), a new deep learning architecture built for learning both spatial and temporal data dependencies in weather data, using fully convolutional layers. Computational experiments using observations of air temperature and rainfall show that our architecture captures spatiotemporal context and outperforms baseline models and the state-of-art architecture for weather forecasting task.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "         <hr />\n",
       "    <table><thead><tr>\n",
       "    <th width=\"25%\">General purpose</th>\n",
       "    <th width=\"25%\">Task-related</th>\n",
       "    <th width=\"25%\">Method-related</th>\n",
       "    <th width=\"25%\">Dataset-related</th>\n",
       "    </thead><tbody>\n",
       "    <tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/convolutional-lstm-network-a-machine-learning\">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</a> <small style=\"background: #eee\">0.852</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> Convolution, ConvLSTM, Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        The goal of precipitation nowcasting is to predict the future rainfall\n",
       "intensity in a local region over a relatively short period of time. Very few\n",
       "previous studies have examined this crucial and chal <a href=\"#\" onclick=\"$('#abstract_ay7qalCYfE').toggle();\">...</a>\n",
       "        <span id=\"abstract_ay7qalCYfE\" style=\"display:none\">lenging weather forecasting\n",
       "problem from the machine learning perspective. In this paper, we formulate\n",
       "precipitation nowcasting as a spatiotemporal sequence forecasting problem in\n",
       "which both the input and the prediction target are spatiotemporal sequences. By\n",
       "extending the fully connected LSTM (FC-LSTM) to have convolutional structures\n",
       "in both the input-to-state and state-to-state transitions, we propose the\n",
       "convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model\n",
       "for the precipitation nowcasting problem. Experiments show that our ConvLSTM\n",
       "network captures spatiotemporal correlations better and consistently\n",
       "outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for\n",
       "precipitation nowcasting.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/statistical-post-processing-of-wind-speed\">Statistical post-processing of wind speed forecasts using convolutional neural networks</a> <small style=\"background: #eee\">0.998</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Current statistical post-processing methods for probabilistic weather forecasting are not capable of using full spatial patterns from the numerical weather prediction (NWP) model. In this paper we inc <a href=\"#\" onclick=\"$('#abstract_ZyL1DrL4SR').toggle();\">...</a>\n",
       "        <span id=\"abstract_ZyL1DrL4SR\" style=\"display:none\">orporate spatial wind speed information by using convolutional neural networks (CNNs) and obtain probabilistic wind speed forecasts in the Netherlands for 48 hours ahead, based on KNMI's Harmonie-Arome NWP model. The CNNs are shown to have higher Brier skill scores for medium to higher wind speeds, as well as a better continuous ranked probability score (CRPS), than fully connected neural networks and quantile regression forests.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/statistical-downscaling-of-temperature\">Statistical Downscaling of Temperature Distributions from the Synoptic Scale to the Mesoscale Using Deep Convolutional Neural Networks</a> <small style=\"background: #eee\">0.980</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep learning, particularly convolutional neural networks for image recognition, has been recently used in meteorology. One of the promising applications is developing a statistical surrogate model th <a href=\"#\" onclick=\"$('#abstract_e0sBdwVxz7').toggle();\">...</a>\n",
       "        <span id=\"abstract_e0sBdwVxz7\" style=\"display:none\">at converts the output images of low-resolution dynamic models to high-resolution images. Our study exhibits a preliminary experiment that evaluates the performance of a model that downscales synoptic temperature fields to mesoscale temperature fields every 6 hours. The deep learning model was trained with operational 22-km gridded global analysis surface winds and temperatures as the input, operational 5-km gridded regional analysis surface temperatures as the desired output, and a target domain covering central Japan. The results confirm that our deep convolutional neural network (DCNN) is capable of estimating the locations of coastlines and mountain ridges in great detail, which are not retained in the inputs, and providing high-resolution surface temperature distributions. For instance, while the average root-mean-square error (RMSE) is 2.7 K between the global and regional analyses at altitudes greater than 1000 m, the RMSE is reduced to 1.0 K, and the correlation coefficient is improved from 0.6 to 0.9 by the surrogate model. Although this study evaluates a surrogate model only for surface temperature, it probably can be improved by augmenting the downscaling variables and vertical profiles. Surrogate models of DCNNs require only a small amount of computational power once their training is finished. Therefore, if the surrogate models are implemented at short time intervals, they will provide high-resolution weather forecast guidance or environment emergency alerts at low cost.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>1. <a href=\"https://paperswithcode.com/paper/a-framework-for-probabilistic-weather\">A framework for probabilistic weather forecast post-processing across models and lead times using machine learning</a> <small style=\"background: #eee\">0.983</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Decision Making\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Forecasting the weather is an increasingly data intensive exercise. Numerical Weather Prediction (NWP) models are becoming more complex, with higher resolutions, and there are increasing numbers of di <a href=\"#\" onclick=\"$('#abstract_EuC9yR7-EQ').toggle();\">...</a>\n",
       "        <span id=\"abstract_EuC9yR7-EQ\" style=\"display:none\">fferent models in operation. While the forecasting skill of NWP models continues to improve, the number and complexity of these models poses a new challenge for the operational meteorologist: how should the information from all available models, each with their own unique biases and limitations, be combined in order to provide stakeholders with well-calibrated probabilistic forecasts to use in decision making? In this paper, we use a road surface temperature example to demonstrate a three-stage framework that uses machine learning to bridge the gap between sets of separate forecasts from NWP models and the 'ideal' forecast for decision support: probabilities of future weather outcomes. First, we use Quantile Regression Forests to learn the error profile of each numerical model, and use these to apply empirically-derived probability distributions to forecasts. Second, we combine these probabilistic forecasts using quantile averaging. Third, we interpolate between the aggregate quantiles in order to generate a full predictive distribution, which we demonstrate has properties suitable for decision support. Our results suggest that this approach provides an effective and operationally viable framework for the cohesive post-processing of weather forecasts across multiple models and lead times to produce a well-calibrated probabilistic output.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/spatio-temporal-graph-convolutional-networks\">Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting</a> <small style=\"background: #eee\">0.834</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Time Series, Time Series Prediction, Traffic Prediction\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> METR-LA, PeMS-M\n",
       "        </p><p>\n",
       "        Timely accurate traffic forecast is crucial for urban traffic control and\n",
       "guidance. Due to the high nonlinearity and complexity of traffic flow,\n",
       "traditional methods cannot satisfy the requirements of  <a href=\"#\" onclick=\"$('#abstract_hL_gCh0gXH').toggle();\">...</a>\n",
       "        <span id=\"abstract_hL_gCh0gXH\" style=\"display:none\">mid-and-long term\n",
       "prediction tasks and often neglect spatial and temporal dependencies. In this\n",
       "paper, we propose a novel deep learning framework, Spatio-Temporal Graph\n",
       "Convolutional Networks (STGCN), to tackle the time series prediction problem in\n",
       "traffic domain. Instead of applying regular convolutional and recurrent units,\n",
       "we formulate the problem on graphs and build the model with complete\n",
       "convolutional structures, which enable much faster training speed with fewer\n",
       "parameters. Experiments show that our model STGCN effectively captures\n",
       "comprehensive spatio-temporal correlations through modeling multi-scale traffic\n",
       "networks and consistently outperforms state-of-the-art baselines on various\n",
       "real-world traffic datasets.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/deep-multi-stations-weather-forecasting\">Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks</a> <small style=\"background: #eee\">0.998</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> Convolution, Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep learning applied to weather forecasting has started gaining popularity because of the progress achieved by data-driven models. The present paper compares four different deep learning architecture <a href=\"#\" onclick=\"$('#abstract_-9DKZbqI0s').toggle();\">...</a>\n",
       "        <span id=\"abstract_-9DKZbqI0s\" style=\"display:none\">s to perform weather prediction on daily data gathered from 18 cities across Europe and spanned over a period of 15 years. The four proposed models investigate the different type of input representations (i.e. tensorial unistream vs. multi-stream matrices) as well as the combination of convolutional neural networks and LSTM (i.e. cascaded vs. ConvLSTM). In particular, we show that a model that uses a multi-stream input representation and that processes each lag individually combined with a cascaded convolution and LSTM is capable of better forecasting than the other compared models. In addition, we show that visualization techniques such as occlusion analysis and score maximization can give an additional insight on the most important features and cities for predicting a particular target feature and city.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/explainable-failure-predictions-with-rnn\">Explainable Failure Predictions with RNN Classifiers based on Time Series Data</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Time Series\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Given key performance indicators collected with fine granularity as time\n",
       "series, our aim is to predict and explain failures in storage environments.\n",
       "Although explainable predictive modeling based on s <a href=\"#\" onclick=\"$('#abstract_5fpvbd9gns').toggle();\">...</a>\n",
       "        <span id=\"abstract_5fpvbd9gns\" style=\"display:none\">piky telemetry data is key\n",
       "in many domains, current approaches cannot tackle this problem. Deep learning\n",
       "methods suitable for sequence modeling and learning temporal dependencies, such\n",
       "as RNNs, are effective, but opaque from an explainability perspective. Our\n",
       "approach first extracts the anomalous spikes from time series as events and\n",
       "then builds an RNN classifier with attention mechanisms to embed the\n",
       "irregularity and frequency of these events. A preliminary evaluation on real\n",
       "world storage environments shows that our approach can predict failures within\n",
       "a 3-day prediction window with comparable accuracy as traditional RNN-based\n",
       "classifiers. At the same time it can explain the predictions by returning the\n",
       "key anomalous events which led to those failure predictions.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>2. <a href=\"https://paperswithcode.com/paper/deep-multi-stations-weather-forecasting\">Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks</a> <small style=\"background: #eee\">0.981</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> Convolution, Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep learning applied to weather forecasting has started gaining popularity because of the progress achieved by data-driven models. The present paper compares four different deep learning architecture <a href=\"#\" onclick=\"$('#abstract_-9DKZbqI0s').toggle();\">...</a>\n",
       "        <span id=\"abstract_-9DKZbqI0s\" style=\"display:none\">s to perform weather prediction on daily data gathered from 18 cities across Europe and spanned over a period of 15 years. The four proposed models investigate the different type of input representations (i.e. tensorial unistream vs. multi-stream matrices) as well as the combination of convolutional neural networks and LSTM (i.e. cascaded vs. ConvLSTM). In particular, we show that a model that uses a multi-stream input representation and that processes each lag individually combined with a cascaded convolution and LSTM is capable of better forecasting than the other compared models. In addition, we show that visualization techniques such as occlusion analysis and score maximization can give an additional insight on the most important features and cities for predicting a particular target feature and city.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/deep-multi-stations-weather-forecasting\">Deep multi-stations weather forecasting: explainable recurrent convolutional neural networks</a> <small style=\"background: #eee\">0.832</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> Convolution, Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Deep learning applied to weather forecasting has started gaining popularity because of the progress achieved by data-driven models. The present paper compares four different deep learning architecture <a href=\"#\" onclick=\"$('#abstract_-9DKZbqI0s').toggle();\">...</a>\n",
       "        <span id=\"abstract_-9DKZbqI0s\" style=\"display:none\">s to perform weather prediction on daily data gathered from 18 cities across Europe and spanned over a period of 15 years. The four proposed models investigate the different type of input representations (i.e. tensorial unistream vs. multi-stream matrices) as well as the combination of convolutional neural networks and LSTM (i.e. cascaded vs. ConvLSTM). In particular, we show that a model that uses a multi-stream input representation and that processes each lag individually combined with a cascaded convolution and LSTM is capable of better forecasting than the other compared models. In addition, we show that visualization techniques such as occlusion analysis and score maximization can give an additional insight on the most important features and cities for predicting a particular target feature and city.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/weather-forecasting-error-in-solar-energy\">Weather Forecasting Error in Solar Energy Forecasting</a> <small style=\"background: #eee\">0.998</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        As renewable distributed energy resources (DERs) penetrate the power grid at\n",
       "an accelerating speed, it is essential for operators to have accurate solar\n",
       "photovoltaic (PV) energy forecasting for effici <a href=\"#\" onclick=\"$('#abstract_IbOfw12p9V').toggle();\">...</a>\n",
       "        <span id=\"abstract_IbOfw12p9V\" style=\"display:none\">ent operations and planning.\n",
       "Generally, observed weather data are applied in the solar PV generation\n",
       "forecasting model while in practice the energy forecasting is based on\n",
       "forecasted weather data. In this paper, a study on the uncertainty in weather\n",
       "forecasting for the most commonly used weather variables is presented. The\n",
       "forecasted weather data for six days ahead is compared with the observed data\n",
       "and the results of analysis are quantified by statistical metrics. In addition,\n",
       "the most influential weather predictors in energy forecasting model are\n",
       "selected. The performance of historical and observed weather data errors is\n",
       "assessed using a solar PV generation forecasting model. Finally, a sensitivity\n",
       "test is performed to identify the influential weather variables whose accurate\n",
       "values can significantly improve the results of energy forecasting.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/physics-guided-recurrent-neural-networks-for\">Physics Guided Recurrent Neural Networks For Modeling Dynamical Systems: Application to Monitoring Water Temperature And Quality In Lakes</a> <small style=\"background: #eee\">0.979</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        In this paper, we introduce a novel framework for combining scientific\n",
       "knowledge within physics-based models and recurrent neural networks to advance\n",
       "scientific discovery in many dynamical systems. We <a href=\"#\" onclick=\"$('#abstract_PtofQu-Oo1').toggle();\">...</a>\n",
       "        <span id=\"abstract_PtofQu-Oo1\" style=\"display:none\"> will first describe the use\n",
       "of outputs from physics-based models in learning a hybrid-physics-data model.\n",
       "Then, we further incorporate physical knowledge in real-world dynamical systems\n",
       "as additional constraints for training recurrent neural networks. We will apply\n",
       "this approach on modeling lake temperature and quality where we take into\n",
       "account the physical constraints along both the depth dimension and time\n",
       "dimension. By using scientific knowledge to guide the construction and learning\n",
       "the data-driven model, we demonstrate that this method can achieve better\n",
       "prediction accuracy as well as scientific consistency of results.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>3. <a href=\"https://paperswithcode.com/paper/neural-networks-for-post-processing-ensemble\">Neural networks for post-processing ensemble weather forecasts</a> <small style=\"background: #eee\">0.981</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> \n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Ensemble weather predictions require statistical post-processing of\n",
       "systematic errors to obtain reliable and accurate probabilistic forecasts.\n",
       "Traditionally, this is accomplished with distributional r <a href=\"#\" onclick=\"$('#abstract_bKZeP2eBO-').toggle();\">...</a>\n",
       "        <span id=\"abstract_bKZeP2eBO-\" style=\"display:none\">egression models in\n",
       "which the parameters of a predictive distribution are estimated from a training\n",
       "period. We propose a flexible alternative based on neural networks that can\n",
       "incorporate nonlinear relationships between arbitrary predictor variables and\n",
       "forecast distribution parameters that are automatically learned in a\n",
       "data-driven way rather than requiring pre-specified link functions. In a case\n",
       "study of 2-meter temperature forecasts at surface stations in Germany, the\n",
       "neural network approach significantly outperforms benchmark post-processing\n",
       "methods while being computationally more affordable. Key components to this\n",
       "improvement are the use of auxiliary predictor variables and station-specific\n",
       "information with the help of embeddings. Furthermore, the trained neural\n",
       "network can be used to gain insight into the importance of meteorological\n",
       "variables thereby challenging the notion of neural networks as uninterpretable\n",
       "black boxes. Our approach can easily be extended to other statistical\n",
       "post-processing and forecasting problems. We anticipate that recent advances in\n",
       "deep learning combined with the ever-increasing amounts of model and\n",
       "observation data will transform the post-processing of numerical weather\n",
       "forecasts in the coming decade.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/precipitation-nowcasting-leveraging\">Precipitation Nowcasting: Leveraging bidirectional LSTM and 1D CNN</a> <small style=\"background: #eee\">0.826</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Time Series, Time Series Forecasting, Weather Forecasting\n",
       "        <b>Methods:</b> Sigmoid Activation, Tanh Activation, LSTM\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Short-term rainfall forecasting, also known as precipitation nowcasting has\n",
       "become a potentially fundamental technology impacting significant real-world\n",
       "applications ranging from flight safety, rainst <a href=\"#\" onclick=\"$('#abstract_k2NsS2kCfT').toggle();\">...</a>\n",
       "        <span id=\"abstract_k2NsS2kCfT\" style=\"display:none\">orm alerts to farm irrigation\n",
       "timings. Since weather forecasting involves identifying the underlying\n",
       "structure in a huge amount of data, deep-learning based precipitation\n",
       "nowcasting has intuitively outperformed the traditional linear extrapolation\n",
       "methods. Our research work intends to utilize the recent advances in deep\n",
       "learning to nowcasting, a multi-variable time series forecasting problem.\n",
       "Specifically, we leverage a bidirectional LSTM (Long Short-Term Memory) neural\n",
       "network architecture which remarkably captures the temporal features and\n",
       "long-term dependencies from historical data. To further our studies, we compare\n",
       "the bidirectional LSTM network with 1D CNN model to prove the capabilities of\n",
       "sequence models over feed-forward neural architectures in forecasting related\n",
       "problems.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/improving-data-driven-global-weather\">Improving data-driven global weather prediction using deep convolutional neural networks on a cubed sphere</a> <small style=\"background: #eee\">0.998</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> Convolution\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        We present a significantly-improved data-driven global weather forecasting framework using a deep convolutional neural network (CNN) to forecast several basic atmospheric variables on a global grid. N <a href=\"#\" onclick=\"$('#abstract_o2bakZSpLJ').toggle();\">...</a>\n",
       "        <span id=\"abstract_o2bakZSpLJ\" style=\"display:none\">ew developments in this framework include an offline volume-conservative mapping to a cubed-sphere grid, improvements to the CNN architecture, and the minimization of the loss function over multiple steps in a prediction sequence. The cubed-sphere remapping minimizes the distortion on the cube faces on which convolution operations are performed and provides natural boundary conditions for padding in the CNN. Our improved model produces weather forecasts that are indefinitely stable and produce realistic weather patterns at lead times of several weeks and longer. For short- to medium-range forecasting, our model significantly outperforms persistence, climatology, and a coarse-resolution dynamical numerical weather prediction (NWP) model. Unsurprisingly, our forecasts are worse than those from a high-resolution state-of-the-art operational NWP system. Our data-driven model is able to learn to forecast complex surface temperature patterns from few input atmospheric state variables. On annual time scales, our model produces a realistic seasonal cycle driven solely by the prescribed variation in top-of-atmosphere solar forcing. Although it is currently less accurate than operational weather forecasting models, our data-driven CNN executes much faster than those models, suggesting that machine learning could prove to be a valuable tool for large-ensemble forecasting.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/stfnets-learning-sensing-signals-from-the\">STFNets: Learning Sensing Signals from the Time-Frequency Perspective with Short-Time Fourier Neural Networks</a> <small style=\"background: #eee\">0.978</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Speech Recognition\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Recent advances in deep learning motivate the use of deep neural networks in\n",
       "Internet-of-Things (IoT) applications. These networks are modelled after signal\n",
       "processing in the human brain, thereby lead <a href=\"#\" onclick=\"$('#abstract_-K6VZXEyCM').toggle();\">...</a>\n",
       "        <span id=\"abstract_-K6VZXEyCM\" style=\"display:none\">ing to significant advantages at\n",
       "perceptual tasks such as vision and speech recognition. IoT applications,\n",
       "however, often measure physical phenomena, where the underlying physics (such\n",
       "as inertia, wireless signal propagation, or the natural frequency of\n",
       "oscillation) are fundamentally a function of signal frequencies, offering\n",
       "better features in the frequency domain. This observation leads to a\n",
       "fundamental question: For IoT applications, can one develop a new brand of\n",
       "neural network structures that synthesize features inspired not only by the\n",
       "biology of human perception but also by the fundamental nature of physics?\n",
       "Hence, in this paper, instead of using conventional building blocks (e.g.,\n",
       "convolutional and recurrent layers), we propose a new foundational neural\n",
       "network building block, the Short-Time Fourier Neural Network (STFNet). It\n",
       "integrates a widely-used time-frequency analysis method, the Short-Time Fourier\n",
       "Transform, into data processing to learn features directly in the frequency\n",
       "domain, where the physics of underlying phenomena leave better foot-prints.\n",
       "STFNets bring additional flexibility to time-frequency analysis by offering\n",
       "novel nonlinear learnable operations that are spectral-compatible. Moreover,\n",
       "STFNets show that transforming signals to a domain that is more connected to\n",
       "the underlying physics greatly simplifies the learning process. We demonstrate\n",
       "the effectiveness of STFNets with extensive experiments. STFNets significantly\n",
       "outperform the state-of-the-art deep learning models in all experiments. A\n",
       "STFNet, therefore, demonstrates superior capability as the fundamental building\n",
       "block of deep neural networks for IoT applications for various sensor inputs.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>4. <a href=\"https://paperswithcode.com/paper/weatherbench-a-benchmark-dataset-for-data\">WeatherBench: A benchmark dataset for data-driven weather forecasting</a> <small style=\"background: #eee\">0.981</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> Linear Regression\n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Data-driven approaches, most prominently deep learning, have become powerful tools for prediction in many domains. A natural question to ask is whether data-driven methods could also be used to predic <a href=\"#\" onclick=\"$('#abstract_Qrgc8OSx5c').toggle();\">...</a>\n",
       "        <span id=\"abstract_Qrgc8OSx5c\" style=\"display:none\">t global weather patterns days in advance. First studies show promise but the lack of a common dataset and evaluation metrics make inter-comparison between studies difficult. Here we present a benchmark dataset for data-driven medium-range weather forecasting, a topic of high scientific interest for atmospheric and computer scientists alike. We provide data derived from the ERA5 archive that has been processed to facilitate the use in machine learning models. We propose simple and clear evaluation metrics which will enable a direct comparison between different methods. Further, we provide baseline scores from simple linear regression techniques, deep learning models, as well as purely physical forecasting models. The dataset is publicly available at https://github.com/pangeo-data/WeatherBench and the companion code is reproducible with tutorials for getting started. We hope that this dataset will accelerate research in data-driven weather forecasting.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr><tr style=\"vertical-align: top\"><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/diffusion-convolutional-recurrent-neural\">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</a> <small style=\"background: #eee\">0.815</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Multivariate Time Series Forecasting, Spatio-Temporal Forecasting, Time Series, Time Series Forecasting, Time Series Prediction, Traffic Prediction\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> METR-LA, PeMS-M\n",
       "        </p><p>\n",
       "        Spatiotemporal forecasting has various applications in neuroscience, climate\n",
       "and transportation domain. Traffic forecasting is one canonical example of such\n",
       "learning task. The task is challenging due  <a href=\"#\" onclick=\"$('#abstract_wjjKCDWT_Q').toggle();\">...</a>\n",
       "        <span id=\"abstract_wjjKCDWT_Q\" style=\"display:none\">to (1) complex spatial dependency on\n",
       "road networks, (2) non-linear temporal dynamics with changing road conditions\n",
       "and (3) inherent difficulty of long-term forecasting. To address these\n",
       "challenges, we propose to model the traffic flow as a diffusion process on a\n",
       "directed graph and introduce Diffusion Convolutional Recurrent Neural Network\n",
       "(DCRNN), a deep learning framework for traffic forecasting that incorporates\n",
       "both spatial and temporal dependency in the traffic flow. Specifically, DCRNN\n",
       "captures the spatial dependency using bidirectional random walks on the graph,\n",
       "and the temporal dependency using the encoder-decoder architecture with\n",
       "scheduled sampling. We evaluate the framework on two real-world large scale\n",
       "road network traffic datasets and observe consistent improvement of 12% - 15%\n",
       "over state-of-the-art baselines.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/detecting-comma-shaped-clouds-for-severe\">Detecting Comma-shaped Clouds for Severe Weather Forecasting using Shape and Motion</a> <small style=\"background: #eee\">0.998</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Meteorologists use shapes and movements of clouds in satellite images as\n",
       "indicators of several major types of severe storms. Satellite imaginary data\n",
       "are in increasingly higher resolution, both spatia <a href=\"#\" onclick=\"$('#abstract_ufPlNNTV3Z').toggle();\">...</a>\n",
       "        <span id=\"abstract_ufPlNNTV3Z\" style=\"display:none\">lly and temporally, making it\n",
       "impossible for humans to fully leverage the data in their forecast. Automatic\n",
       "satellite imagery analysis methods that can find storm-related cloud patterns\n",
       "as soon as they are detectable are in demand. We propose a machine learning and\n",
       "pattern recognition based approach to detect \"comma-shaped\" clouds in satellite\n",
       "images, which are specific cloud distribution patterns strongly associated with\n",
       "the cyclone formulation. In order to detect regions with the targeted movement\n",
       "patterns, our method is trained on manually annotated cloud examples\n",
       "represented by both shape and motion-sensitive features. Sliding windows in\n",
       "different scales are used to ensure that dense clouds will be captured, and we\n",
       "implement effective selection rules to shrink the region of interest among\n",
       "these sliding windows. Finally, we evaluate the method on a hold-out annotated\n",
       "comma-shaped cloud dataset and cross-match the results with recorded storm\n",
       "events in the severe weather database. The validated utility and accuracy of\n",
       "our method suggest a high potential for assisting meteorologists in weather\n",
       "forecasting.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/correlated-time-series-forecasting-using-deep\">Correlated Time Series Forecasting using Deep Neural Networks: A Summary of Results</a> <small style=\"background: #eee\">0.978</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Multi-Task Learning, Time Series, Time Series Forecasting\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Cyber-physical systems often consist of entities that interact with each\n",
       "other over time. Meanwhile, as part of the continued digitization of industrial\n",
       "processes, various sensor technologies are depl <a href=\"#\" onclick=\"$('#abstract_idsP2NDquI').toggle();\">...</a>\n",
       "        <span id=\"abstract_idsP2NDquI\" style=\"display:none\">oyed that enable us to record\n",
       "time-varying attributes (a.k.a., time series) of such entities, thus producing\n",
       "correlated time series. To enable accurate forecasting on such correlated time\n",
       "series, this paper proposes two models that combine convolutional neural\n",
       "networks (CNNs) and recurrent neural networks (RNNs). The first model employs a\n",
       "CNN on each individual time series, combines the convoluted features, and then\n",
       "applies an RNN on top of the convoluted features in the end to enable\n",
       "forecasting. The second model adds additional auto-encoders into the individual\n",
       "CNNs, making the second model a multi-task learning model, which provides\n",
       "accurate and robust forecasting. Experiments on two real-world correlated time\n",
       "series data set suggest that the proposed two models are effective and\n",
       "outperform baselines in most settings.\n",
       "  This report extends the paper \"Correlated Time Series Forecasting using\n",
       "Multi-Task Deep Neural Networks,\" to appear in ACM CIKM 2018, by providing\n",
       "additional experimental results.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td><td style=\"vertical-align: top\">\n",
       "        <div>\n",
       "        <h3>5. <a href=\"https://paperswithcode.com/paper/smart-weather-forecasting-using-machine\">Smart Weather Forecasting Using Machine Learning:A Case Study in Tennessee</a> <small style=\"background: #eee\">0.980</small></h3>\n",
       "        \n",
       "        <p style=\"margin: 0; padding: 0; font-size: 1.1rem\">\n",
       "        <b>Tasks:</b> Weather Forecasting\n",
       "        <b>Methods:</b> \n",
       "        <b>Datasets:</b> \n",
       "        </p><p>\n",
       "        Traditionally, weather predictions are performed with the help of large complex models of physics, which utilize different atmospheric conditions over a long period of time. These conditions are often <a href=\"#\" onclick=\"$('#abstract_KRd3lURlzs').toggle();\">...</a>\n",
       "        <span id=\"abstract_KRd3lURlzs\" style=\"display:none\"> unstable because of perturbations of the weather system, causing the models to provide inaccurate forecasts. The models are generally run on hundreds of nodes in a large High Performance Computing (HPC) environment which consumes a large amount of energy. In this paper, we present a weather prediction technique that utilizes historical data from multiple weather stations to train simple machine learning models, which can provide usable forecasts about certain weather conditions for the near future within a very short period of time. The models can be run on much less resource intensive environments. The evaluation results show that the accuracy of the models is good enough to be used alongside the current state-of-the-art techniques. Furthermore, we show that it is beneficial to leverage the weather station data from multiple neighboring areas over the data of only the area for which weather forecasting is being performed.</span>\n",
       "        </div>\n",
       "        \n",
       "        </div>\n",
       "        </td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_ids = random.sample(list(paper_id2paper.keys()), 3)\n",
    "\n",
    "for pid in random_ids:\n",
    "    display(HTML(get_multi_view_html(pid, show_details=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
